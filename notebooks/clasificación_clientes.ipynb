{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from dateutil import parser\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "sscaler = StandardScaler()\n",
    "rscaler = RobustScaler()\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import Birch\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura del archivo excel con la información de los clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>CIIU</th>\n",
       "      <th>CODIGOCLIE</th>\n",
       "      <th>Mult. de potencias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LA INDUSTRIA HARINERA S.A</td>\n",
       "      <td>C1061.11</td>\n",
       "      <td>1401867926</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONFITECA</td>\n",
       "      <td>C1073.21</td>\n",
       "      <td>1490000744</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUCESORES DE JACOBO PAREDES M. S.A.</td>\n",
       "      <td>C1074.01</td>\n",
       "      <td>1490000688</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AC BEBIDAS, S. DE R.L. DE C.V.</td>\n",
       "      <td>C1104.01</td>\n",
       "      <td>1490001175</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S.J. JERSEY ECUATORIANO C.A.</td>\n",
       "      <td>C1311.02</td>\n",
       "      <td>1490000515</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>CIRION TECHNOLOGIES ECUADOR S.A.</td>\n",
       "      <td>J6190.02</td>\n",
       "      <td>1410020880</td>\n",
       "      <td>1140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>ECUATORIANA DE ARTEFACTOS S.A. ECASA</td>\n",
       "      <td>C2750.01</td>\n",
       "      <td>1490000693</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>INTEXDECOR S.A.</td>\n",
       "      <td>G4641.11</td>\n",
       "      <td>1490001644</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>INTELA INDUSTRIA TEXTIL LATINOAMERICANA CIA. L...</td>\n",
       "      <td>C1312.01</td>\n",
       "      <td>1410062892</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>FABRILACTEOS CIA. LTDA.</td>\n",
       "      <td>C1050.05</td>\n",
       "      <td>1490002155</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Nombre      CIIU  CODIGOCLIE  \\\n",
       "0                            LA INDUSTRIA HARINERA S.A  C1061.11  1401867926   \n",
       "1                                            CONFITECA  C1073.21  1490000744   \n",
       "2                 SUCESORES DE JACOBO PAREDES M. S.A.   C1074.01  1490000688   \n",
       "3                       AC BEBIDAS, S. DE R.L. DE C.V.  C1104.01  1490001175   \n",
       "4                        S.J. JERSEY ECUATORIANO C.A.   C1311.02  1490000515   \n",
       "..                                                 ...       ...         ...   \n",
       "209                   CIRION TECHNOLOGIES ECUADOR S.A.  J6190.02  1410020880   \n",
       "210               ECUATORIANA DE ARTEFACTOS S.A. ECASA  C2750.01  1490000693   \n",
       "211                                    INTEXDECOR S.A.  G4641.11  1490001644   \n",
       "212  INTELA INDUSTRIA TEXTIL LATINOAMERICANA CIA. L...  C1312.01  1410062892   \n",
       "213                            FABRILACTEOS CIA. LTDA.  C1050.05  1490002155   \n",
       "\n",
       "     Mult. de potencias  \n",
       "0                1100.0  \n",
       "1                1100.0  \n",
       "2                1100.0  \n",
       "3                 400.0  \n",
       "4                 800.0  \n",
       "..                  ...  \n",
       "209              1140.0  \n",
       "210                 1.0  \n",
       "211              1000.0  \n",
       "212              1100.0  \n",
       "213               120.0  \n",
       "\n",
       "[214 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tabla_final = pd.read_excel(\"archivos_entrada_script/tabla_final.xlsx\", sheet_name=\"Hoja2\", dtype={\"CODIGOCLIE\":str})\n",
    "df_tabla_final[\"CODIGOCLIE\"] = df_tabla_final[\"CODIGOCLIE\"].astype(\"string\")\n",
    "df_tabla_final = df_tabla_final.iloc[:,2:6]\n",
    "df_tabla_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StringArray>\n",
      "['1401867926', '1490000744', '1490000688', '1490001175', '1490000515',\n",
      " '1401337167', '1490002225', '1401582655', '1490001247', '1401282968',\n",
      " ...\n",
      " '1401229975', '1401954998', '1490000719', '1401940609', '1410026628',\n",
      " '1410020880', '1490000693', '1490001644', '1410062892', '1490002155']\n",
      "Length: 214, dtype: string\n"
     ]
    }
   ],
   "source": [
    "clientes_unicos = df_tabla_final[\"CODIGOCLIE\"].unique()\n",
    "print(clientes_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intentar_abrir_archivo_datos(path_archivo):\n",
    "\n",
    "    df_archivo_telem_tab = pd.DataFrame([1,2,3], columns=[\"prueba\"])\n",
    "    df_archivo_telem_pc = pd.DataFrame([1,2,3], columns=[\"prueba\"])\n",
    "    df_archivo_telem_c = pd.DataFrame([1,2,3], columns=[\"prueba\"])\n",
    "\n",
    "    # Intentar leer el archivo con separador 'tab'\n",
    "    try:\n",
    "        #print(\"Leyendo con tab\")\n",
    "        df_archivo_telem_tab = pd.read_csv(path_archivo,\n",
    "                                            sep=\"\\t\",\n",
    "                                            #decimal=\",\",\n",
    "                                            skiprows=11,\n",
    "                                            #na_values=\"N/D\",\n",
    "                                            encoding=\"utf-16\",\n",
    "                                            #on_bad_lines=\"skip\",\n",
    "                                            encoding_errors=\"ignore\" \n",
    "                                            ) \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Intentar leer el archivo con separador 'punto y coma'\n",
    "    try:\n",
    "        #print(\"Leyendo con ;\")\n",
    "        df_archivo_telem_pc = pd.read_csv(path_archivo,\n",
    "                                            sep=\";\",\n",
    "                                            #decimal=\",\",\n",
    "                                            skiprows=11,\n",
    "                                            #na_values=\"N/D\",\n",
    "                                            #encoding=\"utf-16\",\n",
    "                                            #on_bad_lines=\"skip\",\n",
    "                                            encoding_errors=\"ignore\" \n",
    "                                            )\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Intentar leer el archivo con separador 'coma'\n",
    "    try:\n",
    "        #print(\"Leyendo con ,\")\n",
    "        df_archivo_telem_c = pd.read_csv(path_archivo,\n",
    "                                            sep=\",\",\n",
    "                                            #decimal=\",\",\n",
    "                                            skiprows=11,\n",
    "                                            #na_values=\"N/D\",\n",
    "                                            #encoding=\"utf-16\",\n",
    "                                            #on_bad_lines=\"skip\",\n",
    "                                            encoding_errors=\"ignore\" \n",
    "                                            )\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    if len(df_archivo_telem_tab.columns) > 1:\n",
    "        df_archivo_telem = df_archivo_telem_tab.copy()\n",
    "    elif len(df_archivo_telem_pc.columns) > 1:\n",
    "        df_archivo_telem = df_archivo_telem_pc.copy()\n",
    "    else:\n",
    "        df_archivo_telem = df_archivo_telem_c.copy()\n",
    "\n",
    "    return df_archivo_telem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extracción de los archivos de cada grupo de clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Extracción de los archivos con las mediciones mensuales del primer grupo de clientes\n",
    "\n",
    "Estos clientes están clasificados por CUEN, y el formato de sus archivos varían, el procedimiento a seguir será:\n",
    "1. Iterar sobre cada código de cliente\n",
    "2. Buscar sus archivos de datos mensuales\n",
    "3. Unificar todos en un solo archivo\n",
    "4. El identificador a usar es el código de cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediciones_clientes_g1 = r\"mediciones_originales/mediciones_por_mes_g1\"\n",
    "archivos_mediciones_g1 = list(os.scandir(mediciones_clientes_g1))\n",
    "columnas_extraer_g1 = [\"Fecha\",\"Demanda activa DEL\",\"Demanda reactiva DEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes único encontrados en la carpeta de mediciones del grupo uno: 314\n"
     ]
    }
   ],
   "source": [
    "clientes_unicos_g1 = set()\n",
    "\n",
    "for medicion in archivos_mediciones_g1:\n",
    "    cliente = medicion.name.split('-')[1]\n",
    "    clientes_unicos_g1.add(cliente)\n",
    "\n",
    "print(f\"Clientes único encontrados en la carpeta de mediciones del grupo uno: {len(clientes_unicos_g1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando clientes del grupo 01: 100%|██████████| 314/314 [00:33<00:00,  9.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar los clientes con sus respectivos datos\n",
    "dict_dfs_clientes_g1 = {}\n",
    "\n",
    "# Iterar sobre cada cliente\n",
    "for cliente in tqdm(clientes_unicos_g1, desc=\"Procesando clientes del grupo 01\"):\n",
    "    datos_cliente = []\n",
    "    # Iterar sobre cada archivo de medicion del grupo 01\n",
    "    for medicion in archivos_mediciones_g1:\n",
    "        if cliente == medicion.name.split(\"-\")[1]:\n",
    "            df_cliente = intentar_abrir_archivo_datos(f\"{mediciones_clientes_g1}/{medicion.name}\")\n",
    "            datos_cliente.extend(df_cliente[columnas_extraer_g1].values)\n",
    "\n",
    "    # Convertir a DataFrame los datos concatenados\n",
    "    df_datos_anual_cliente = pd.DataFrame(datos_cliente, columns=columnas_extraer_g1)\n",
    "    \n",
    "    # Almacenar en el diccionario (Clave->Cliente   Valor->DataFrame)\n",
    "    dict_dfs_clientes_g1[cliente]=df_datos_anual_cliente\n",
    "    \n",
    "    # Eliminar dataframe concatenado para liberar memoria\n",
    "    del df_datos_anual_cliente\n",
    "    #df_datos_anual_cliente.to_csv(f\"mediciones_por_anio/g1_perfil_carga_anual-{cliente}-2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Extracción de los archivos con las mediciones mensuales del segundo grupo de clientes\n",
    "\n",
    "De estos clientes tenemos carpetas con sus mediciones por mes, no existe tabla de excel inicial, se procederá a realizar lo siguiente:\n",
    "1. Iterar sobre cada carpeta (cliente)\n",
    "2. Obtener los datos de sus 12 meses\n",
    "3. Unificar en un único archivo anual\n",
    "4. Se usará el nombre del cliente como identificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediciones_clientes_g2 = \"mediciones_originales/mediciones_por_mes_g2\"\n",
    "archivos_mediciones_g2 = list(os.scandir(mediciones_clientes_g2))\n",
    "columnas_extraer_g2 = [\"Fecha\", \"AS (kWh)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes único encontrados en la carpeta de mediciones del grupo uno: 75\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clientes único encontrados en la carpeta de mediciones del grupo uno: {len(archivos_mediciones_g2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando clientes del grupo 02: 100%|██████████| 75/75 [00:04<00:00, 17.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar los clientes con sus datos\n",
    "dict_dfs_clientes_g2 = {}\n",
    "\n",
    "# Iterar sobre cada cliente\n",
    "for archivos_cliente in tqdm(archivos_mediciones_g2, desc=\"Procesando clientes del grupo 02\"):\n",
    "    nombre_cli = archivos_cliente.name.strip()\n",
    "    df_concat = pd.DataFrame()\n",
    "\n",
    "    # Obtener los archivos de las mediciones mensuales del cliente\n",
    "    mediciones_mensuales_cliente = os.scandir(rf\"{mediciones_clientes_g2}/{nombre_cli}\")\n",
    "\n",
    "    for medicion in mediciones_mensuales_cliente:\n",
    "        medicion_mensual = pd.read_csv(rf\"{mediciones_clientes_g2}/{nombre_cli}/{medicion.name}\", sep=\";\", skiprows=2, encoding='ISO-8859-1')\n",
    "        medicion_mensual = medicion_mensual[columnas_extraer_g2]\n",
    "        df_concat = pd.concat([df_concat, medicion_mensual])\n",
    "\n",
    "    # Almacenar en el diccionario (Clave->Cliente   Valor->DataFrame)\n",
    "    dict_dfs_clientes_g2[nombre_cli] = df_concat\n",
    "    \n",
    "    # Eliminar dataframe concatenado para liberar memoria\n",
    "    del df_concat\n",
    "    #df_concat.to_csv(rf\"mediciones_por_anio/g2_perfil_carga_anual-{nombre_cli}-2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocesamiento de los datos\n",
    "\n",
    "Ahora tenemos todos los datos unificados anualmente por cada cliente, tenemos que limpiar y preprocesar, realizar las siguientes tareas:\n",
    "1. Calcular la potencia aparente (resultado de aplicar teorema pitágoras sobre potencia activa y reactiva)\n",
    "2. Separar la columna 'fecha' en dos columnas 'fecha' y 'hora', fecha va a tener formato 'año/mes/dia' y hora el formato 'hh:mm'\n",
    "3. Excluir aquellos registros que correspondan a fechas de sábado, domingo o días de feriado nacional\n",
    "4. Normalizar los datos para que todos estén en la misma escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
      "DatetimeIndex(['2023-07-02', '2023-02-20', '2023-02-21', '2023-04-07',\n",
      "               '2023-05-01', '2023-05-26', '2023-08-11', '2023-10-09',\n",
      "               '2023-10-02', '2023-10-03', '2023-12-25'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "feriados_nacionales = [\"2/7/2023\", \"20/2/2023\", \"21/2/2023\", \"7/4/2023\", \"1/5/2023\", \\\n",
    "                       \"26/5/2023\", \"11/8/2023\", \"9/10/2023\", \"2/10/2023\", \"3/10/2023\", \"25/12/2023\"]\n",
    "feriados_nacionales = pd.to_datetime(feriados_nacionales, format='%d/%m/%Y')\n",
    "\n",
    "dict_meses = {\"01\": \"Enero\",\n",
    "              \"02\": \"Febrero\",\n",
    "              \"03\": \"Marzo\",\n",
    "              \"04\": \"Abril\",\n",
    "              \"05\": \"Mayo\",\n",
    "              \"06\": \"Junio\",\n",
    "              \"07\": \"Julio\",\n",
    "              \"08\": \"Agosto\",\n",
    "              \"09\": \"Septiembre\",\n",
    "              \"10\": \"Octubre\",\n",
    "              \"11\": \"Noviembre\",\n",
    "              \"12\": \"Diciembre\"}\n",
    "\n",
    "print(list(dict_meses.keys()))\n",
    "print(feriados_nacionales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fecha_formato_unico(fecha_str):\n",
    "\n",
    "    # Poner separador único el '/' y año únicamente 2023\n",
    "    fecha_str = fecha_str.replace('-','/').replace('2024','2023')\n",
    "\n",
    "    if len(fecha_str.split('/')[0]) == 4: # Cuando el formato es año/mes/día\n",
    "        return fecha_str\n",
    "    elif len(fecha_str.split('/')[0]) != 4: # Cuando el formato es día/mes/año\n",
    "        seps = fecha_str.split('/')\n",
    "        return f\"{seps[-1]}/{seps[1]}/{seps[0]}\"\n",
    "    \n",
    "\n",
    "def recortar_valores_atipicos(df, columna_valor):\n",
    "    # Calcular los cuartiles y el IQR\n",
    "    Q1 = df[columna_valor].quantile(0.25)\n",
    "    Q3 = df[columna_valor].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Definir los límites superior e inferior\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Aplicar el recorte\n",
    "    df[columna_valor] = df[columna_valor].clip(lower=limite_inferior, upper=limite_superior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediciones_anuales_clientes = \"mediciones_por_anio\"\n",
    "archivos_mediciones_anuales = list(os.scandir(mediciones_anuales_clientes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 - Transformación columna fecha archivos anuales grupo 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dfs_procesados_g1 = {}\n",
    "\n",
    "for cliente, df_archivo_g1 in dict_dfs_clientes_g1.items():\n",
    "\n",
    "    # Transformar columna fecha a cadena\n",
    "    df_archivo_g1[\"Fecha\"] = df_archivo_g1[\"Fecha\"].astype(\"string\")\n",
    "\n",
    "    # Eliminar los valores nulos en la columna 'Fecha'\n",
    "    df_archivo_g1 = df_archivo_g1.dropna(subset=\"Fecha\")\n",
    "\n",
    "    # Separar para obtener columna Hora\n",
    "    df_archivo_g1[\"Hora\"] = df_archivo_g1[\"Fecha\"].apply(lambda x: x.split()[1].strip())\n",
    "\n",
    "    # Separar para obtener columna Fecha\n",
    "    df_archivo_g1[\"Fecha\"] = df_archivo_g1[\"Fecha\"].apply(lambda x: x.split()[0].strip())\n",
    "\n",
    "    # Transformar la columna Fecha a un formato único\n",
    "    df_archivo_g1[\"Fecha\"] = df_archivo_g1[\"Fecha\"].apply(fecha_formato_unico)\n",
    "\n",
    "    # Debido a que a veces se ponen datos del 2024 para reemplazar los faltantes del 2023\n",
    "    # debemos descartar la fecha 29 de febrero, pues en 2023 no existe\n",
    "    df_archivo_g1 = df_archivo_g1[df_archivo_g1[\"Fecha\"] != \"2023/02/29\"]\n",
    "    \n",
    "    # Eliminar duplicados y conservar el original del 2023\n",
    "    df_archivo_g1[\"Fecha-Hora\"] = df_archivo_g1[\"Fecha\"] + \" \" + df_archivo_g1[\"Hora\"]\n",
    "    df_archivo_g1 = df_archivo_g1.drop_duplicates(subset=\"Fecha-Hora\", keep=\"first\")\n",
    "\n",
    "    # Transformar columna Fecha a datetime\n",
    "    df_archivo_g1[\"Fecha\"] = pd.to_datetime(df_archivo_g1[\"Fecha\"], format='%Y/%m/%d')\n",
    "\n",
    "    # Obtener la potencia aparente\n",
    "    df_archivo_g1[\"Potencia_aparente\"] = np.sqrt((df_archivo_g1[\"Demanda activa DEL\"]**2) + (df_archivo_g1[\"Demanda reactiva DEL\"]**2))\n",
    "\n",
    "    # Eliminar días feriados y días de fin de semana\n",
    "    df_archivo_g1 = df_archivo_g1[~df_archivo_g1['Fecha'].isin(feriados_nacionales) & ~df_archivo_g1['Fecha'].dt.weekday.isin([5, 6])]\n",
    "\n",
    "    # Interpolar valores nulos usando una función polinomial\n",
    "    df_archivo_g1[\"Potencia_aparente\"] = df_archivo_g1[\"Potencia_aparente\"].interpolate(method='polynomial', order=3)\n",
    "\n",
    "    # Conservar solo las columnas de interés\n",
    "    df_archivo_g1 = df_archivo_g1[[\"Fecha\", \"Hora\", \"Potencia_aparente\"]]\n",
    "\n",
    "    # Escalar las mediciones\n",
    "    df_archivo_g1[\"Potencia_aparente_escalada\"] = mmscaler.fit_transform(df_archivo_g1[[\"Potencia_aparente\"]])\n",
    "\n",
    "    # Guardar en un nuevo diccionario los datos procesados\n",
    "    dict_dfs_procesados_g1[cliente] = df_archivo_g1\n",
    "    \n",
    "    # Liberar memoria\n",
    "    del df_archivo_g1\n",
    "    \n",
    "del dict_dfs_clientes_g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 - Transformación columna fecha archivos anuales grupo 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dfs_procesados_g2 = {}\n",
    "\n",
    "for cliente, df_archivo_g2 in dict_dfs_clientes_g2.items():\n",
    "\n",
    "    # Transformar columna fecha a cadena\n",
    "    df_archivo_g2[\"Fecha\"] = df_archivo_g2[\"Fecha\"].astype(\"string\")\n",
    "\n",
    "    # Eliminar registros que contienen el total\n",
    "    df_archivo_g2 = df_archivo_g2[~df_archivo_g2[\"Fecha\"].str.contains(\"Total\")]\n",
    "\n",
    "    # Eliminar los valores nulos en la columna 'Fecha'\n",
    "    df_archivo_g2 = df_archivo_g2.dropna(subset=\"Fecha\")\n",
    "\n",
    "    # Separar para obtener columna Hora\n",
    "    df_archivo_g2[\"Hora\"] = df_archivo_g2[\"Fecha\"].apply(lambda x: x.split()[1].strip())\n",
    "\n",
    "    # Separar para obtener columna Fecha\n",
    "    df_archivo_g2[\"Fecha\"] = df_archivo_g2[\"Fecha\"].apply(lambda x: x.split()[0].strip())\n",
    "\n",
    "    # Eliminar duplicados y conservar el original del 2023\n",
    "    df_archivo_g2[\"Fecha-Hora\"] = df_archivo_g2[\"Fecha\"] + \" \" + df_archivo_g2[\"Hora\"]\n",
    "    df_archivo_g2[\"Fecha-Hora\"] = pd.to_datetime(df_archivo_g2[\"Fecha-Hora\"], yearfirst=True)\n",
    "    df_archivo_g2 = df_archivo_g2.drop_duplicates(subset=\"Fecha-Hora\", keep=\"first\")\n",
    "\n",
    "    # Restar un timedelta de 15 a todas las fechas (Solo en este caso por que la ultima fecha)\n",
    "    # se pasa al siguiente mes\n",
    "    df_archivo_g2[\"Fecha-Hora\"] = df_archivo_g2[\"Fecha-Hora\"] - pd.Timedelta(minutes=15)\n",
    "\n",
    "    # Separar nuevamente para obtener columna Hora\n",
    "    df_archivo_g2[\"Hora\"] = df_archivo_g2[\"Fecha-Hora\"].astype(\"string\").apply(lambda x: x.split()[1][:-3].strip())\n",
    "\n",
    "    # Separar nuevamente para obtener columna Fecha\n",
    "    df_archivo_g2[\"Fecha\"] = df_archivo_g2[\"Fecha-Hora\"].astype(\"string\").apply(lambda x: x.split()[0].strip())\n",
    "\n",
    "    # Transformar la columna Fecha a un formato único\n",
    "    df_archivo_g2[\"Fecha\"] = df_archivo_g2[\"Fecha\"].apply(fecha_formato_unico)\n",
    "\n",
    "    # Debido a que a veces se ponen datos del 2024 para reemplazar los faltantes del 2023\n",
    "    # debemos descartar la fecha 29 de febrero, pues en 2023 no existe\n",
    "    df_archivo_g2 = df_archivo_g2[df_archivo_g2[\"Fecha\"] != \"2023/02/29\"]\n",
    "\n",
    "    # Transformar columna Fecha a datetime\n",
    "    df_archivo_g2[\"Fecha\"] = pd.to_datetime(df_archivo_g2[\"Fecha\"], format='%Y/%m/%d')\n",
    "\n",
    "    # Limpiar la columna 'SE (KVah)'\n",
    "    df_archivo_g2[\"AS (kWh)\"] = df_archivo_g2[\"AS (kWh)\"].astype(\"string\").str.replace(\",\", \"\").replace('\"','')\n",
    "    df_archivo_g2[\"AS (kWh)\"] = df_archivo_g2[\"AS (kWh)\"].astype(\"float\")\n",
    "\n",
    "    # Obtener la potencia aparente\n",
    "    df_archivo_g2[\"Potencia_aparente\"] = df_archivo_g2[\"AS (kWh)\"] * 4\n",
    "\n",
    "    # Eliminar días feriados y días de fin de semana\n",
    "    df_archivo_g2 = df_archivo_g2[~df_archivo_g2['Fecha'].isin(feriados_nacionales) & ~df_archivo_g2['Fecha'].dt.weekday.isin([5, 6])]\n",
    "\n",
    "    # Interpolar valores nulos usando una función polinomial\n",
    "    df_archivo_g2[\"Potencia_aparente\"] = df_archivo_g2[\"Potencia_aparente\"].interpolate(method='polynomial', order=3)\n",
    "\n",
    "    # Conservar solo las columnas de interés\n",
    "    df_archivo_g2 = df_archivo_g2[[\"Fecha\", \"Hora\", \"Potencia_aparente\"]]\n",
    "\n",
    "    # Escalar las mediciones\n",
    "    df_archivo_g2[\"Potencia_aparente_escalada\"] = mmscaler.fit_transform(df_archivo_g2[[\"Potencia_aparente\"]])\n",
    "\n",
    "    # Guardar en un nuevo diccionario los datos procesados\n",
    "    dict_dfs_procesados_g2[cliente] = df_archivo_g2\n",
    "    \n",
    "    # Liberar memoria\n",
    "    del df_archivo_g2\n",
    "    \n",
    "del dict_dfs_clientes_g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generación de los entregables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_coords_curva_tipo(df):\n",
    "\n",
    "    # Agrupar por hora y aplicar mediana\n",
    "    df_grouped = df.groupby(\"Hora\")[\"Potencia_aparente_escalada\"].apply(np.mean).sort_index(ascending=True).reset_index(drop=False)\n",
    "\n",
    "    # Retornar el array con los 96 valores de demanda\n",
    "    return df_grouped\n",
    "\n",
    "def obtener_coords_dia_demanda_max(df):\n",
    "\n",
    "    # Obtener el máximo valor de potencia aparente\n",
    "    max_potencia = df['Potencia_aparente_escalada'].max()\n",
    "\n",
    "    # Encontrar la fecha correspondiente a la máxima potencia aparente\n",
    "    fecha_max_potencia = df[df['Potencia_aparente_escalada'] == max_potencia]['Fecha'].iloc[0]\n",
    "\n",
    "    # Filtrar los registros correspondientes a esa fecha\n",
    "    df_max_fecha = df[df['Fecha'] == fecha_max_potencia]\n",
    "\n",
    "    # Ordenar el resultado de manera ascendente por 'Hora'\n",
    "    df_max_fecha = df_max_fecha.sort_values(by=\"Hora\", ascending=True)\n",
    "\n",
    "    return fecha_max_potencia, df_max_fecha[[\"Hora\",\"Potencia_aparente_escalada\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_curva_tipo(df, cod_cli, path):\n",
    "\n",
    "    # Generar el gráfico de la curva tipo\n",
    "    _ = plt.figure(figsize=(16, 6))\n",
    "    _ = plt.plot(df[\"Hora\"], df[\"Potencia_aparente_escalada\"], marker='o', color='b', linestyle='-', label='Potencia Aparente Escalada')\n",
    "    _ = plt.title(f'Curva tipo cliente {cod_cli}')\n",
    "    _ = plt.xlabel('Hora')\n",
    "    _ = plt.ylabel('Potencia Aparente Escalada')\n",
    "    _ = plt.grid(True)\n",
    "\n",
    "    # Rotar etiquetas para que no se vea acumulado el eje X\n",
    "    _ = plt.xticks(df[\"Hora\"].values[::2], rotation=45)\n",
    "\n",
    "    # Para que no se distorsione la dimenisión del eje Y\n",
    "    _ = plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "    # Evitar recortes en las etiquetas\n",
    "    _ = plt.tight_layout()\n",
    "\n",
    "    # Guardar la gráfica en un directorio\n",
    "    _ = plt.savefig(f\"{path}/curva_tipo_{cod_cli}.png\", format='png')  # Puedes cambiar el formato a 'jpg', 'pdf', etc.\n",
    "    _ = plt.savefig(f\"curvas_tipo_clientes/curva_tipo_{cod_cli}.png\", format='png')  # Puedes cambiar el formato a 'jpg', 'pdf', etc.\n",
    "    \n",
    "    # Cerrar la figura después de guardarla para liberar recursos\n",
    "    _ = plt.close()  \n",
    "\n",
    "def graficar_dia_max_demanda(df, cod_cli, path, fecha):\n",
    "\n",
    "    # Graficar la potencia aparente escalada a lo largo del día\n",
    "    _ = plt.figure(figsize=(16, 6))\n",
    "    _ = plt.plot(df[\"Hora\"], df[\"Potencia_aparente_escalada\"], marker='o', color='r', linestyle='-', label=f'Potencia Aparente Escalada')\n",
    "    _ = plt.title(f'Curva del día de demanda máxima {fecha} para cliente {cod_cli}')\n",
    "    _ = plt.xlabel('Hora')\n",
    "    _ = plt.ylabel('Potencia Aparente Escalada')\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.legend()\n",
    "\n",
    "    # Rotar etiquetas para que no se vea acumulado el eje X\n",
    "    _ = plt.xticks(df[\"Hora\"].values[::2], rotation=45)\n",
    "\n",
    "    # Para que no se distorsione la dimenisión del eje Y\n",
    "    _ = plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "    # Evitar recortes en las etiquetas\n",
    "    _ = plt.tight_layout()\n",
    "\n",
    "    # Guardar la gráfica en un archivo (por ejemplo, como archivo PNG)\n",
    "    _ = plt.savefig(f\"{path}/curva_dia_demanda_max_{cod_cli}.png\", format='png')  # Puedes cambiar el formato a 'jpg', 'pdf', etc.\n",
    "    \n",
    "    # Cerrar la figura después de guardarla para liberar recursos\n",
    "    _ = plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_horas(df, columna_hora=\"Hora\", columna_valor=\"Potencia_aparente_escalada\"):\n",
    "\n",
    "    # Convertir la columna Hora a tipo datetime\n",
    "    df[\"Hora\"] = pd.to_datetime(df[columna_hora], format=\"%H:%M\")\n",
    "\n",
    "    # Agrupar por hora y tomar el punto medio (hh:30)\n",
    "    df[\"Hora\"] = df[\"Hora\"].dt.floor(\"H\") + pd.Timedelta(minutes=30)\n",
    "\n",
    "    # Recortar a HH:MM\n",
    "    df[\"Hora\"] = df[\"Hora\"].astype(\"string\").apply(lambda x: x.split()[1][:-3])\n",
    "\n",
    "    # Agrupar por la nueva columna de hora y calcular el promedio de los valores\n",
    "    return df.groupby(\"Hora\")[columna_valor].apply(np.mean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_30_min(df, columna_hora=\"Hora\", columna_valor=\"Potencia_aparente_escalada\"):\n",
    "\n",
    "    # Convertir la columna Hora a tipo datetime\n",
    "    df[\"Hora\"] = pd.to_datetime(df[columna_hora], format=\"%H:%M\")\n",
    "\n",
    "    # Redondear hacia arriba al final del intervalo de 30 minutos\n",
    "    df[\"Hora\"] = df[\"Hora\"] + pd.Timedelta(minutes=30)\n",
    "    df[\"Hora\"] = df[\"Hora\"].dt.floor(\"H\") + (df[\"Hora\"].dt.minute // 30) * pd.Timedelta(minutes=30)\n",
    "\n",
    "    # Recortar a HH:MM\n",
    "    df[\"Hora\"] = df[\"Hora\"].astype(\"string\").apply(lambda x: x.split()[1][:-3])\n",
    "\n",
    "    # Agrupar por la nueva columna de hora y calcular el promedio de los valores\n",
    "    return df.groupby(\"Hora\")[columna_valor].apply(np.mean).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso de agregación y obtención de las curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_entregables = r\"entregables_por_cliente\"\n",
    "\n",
    "dict_todos_los_clientes = dict_dfs_procesados_g1 | dict_dfs_procesados_g2\n",
    "del dict_dfs_procesados_g1\n",
    "del dict_dfs_procesados_g2\n",
    "\n",
    "registros_curvas_todas = []\n",
    "\n",
    "for cliente, df_medicion_anual in dict_todos_los_clientes.items():\n",
    "\n",
    "    # Lista para almacenar todos los valores de la curva tipo del cliente\n",
    "    registros_curva_cliente = []\n",
    "\n",
    "    # Directorio entregables cliente\n",
    "    dir_entregables_cli = fr\"{path_entregables}/{cliente}\"\n",
    "\n",
    "    # Crear el directorio para los entregables (Si no existe)\n",
    "    if not os.path.exists(dir_entregables_cli):\n",
    "        os.makedirs(dir_entregables_cli)\n",
    "\n",
    "    # Generar el archivo con los datos de la curva tipo\n",
    "    df_curva_tipo = obtener_coords_curva_tipo(df_medicion_anual)\n",
    "    df_curva_tipo = agrupar_30_min(df_curva_tipo)\n",
    "    df_curva_tipo.to_csv(f\"{dir_entregables_cli}/datos_curva_tipo_{cliente}.csv\", index=False)\n",
    "\n",
    "    # Guardar los datos en una lista\n",
    "    registros_curva_cliente.append(cliente)\n",
    "    for valor in df_curva_tipo[\"Potencia_aparente_escalada\"].values:\n",
    "        registros_curva_cliente.append(valor)\n",
    "\n",
    "    # Generar el archivo con los datos de la curva del día que hubo la demanda máxima\n",
    "    fecha_max_dem, df_curva_dia_dem_max = obtener_coords_dia_demanda_max(df_medicion_anual)\n",
    "    df_curva_dia_dem_max = df_curva_dia_dem_max.sort_values(by=\"Hora\", ascending=True)\n",
    "    df_curva_dia_dem_max.to_csv(f\"{dir_entregables_cli}/datos_curva_dia_demanda_max.csv\", index=False)\n",
    "\n",
    "    # Generar la gráfica de la curva tipo\n",
    "    graficar_curva_tipo(df_curva_tipo, cliente, dir_entregables_cli)\n",
    "\n",
    "    # Generar la gráfica de la curva del día de demanda máxima\n",
    "    graficar_dia_max_demanda(df_curva_dia_dem_max, cliente, dir_entregables_cli, str(fecha_max_dem).split()[0])\n",
    "\n",
    "    # Generar un archivo plano con la demanda máximo y mínima\n",
    "    open(rf'{dir_entregables_cli}/Potencia_max_min.txt', 'w')\\\n",
    "        .write(f'Pot_aparente_max: {df_medicion_anual[\"Potencia_aparente\"].max()}\\nPot_aparente_min: {df_medicion_anual[\"Potencia_aparente\"].min()}')\n",
    "\n",
    "    # Guardar la lista con los registros de un cliente en otra lista\n",
    "    registros_curvas_todas.append(registros_curva_cliente)\n",
    "\n",
    "columnas_df_todas_las_curvas = [\"Cliente\"]\n",
    "columnas_df_todas_las_curvas.extend(df_curva_tipo[\"Hora\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dict_todos_los_clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cliente</th>\n",
       "      <th>00:00</th>\n",
       "      <th>00:30</th>\n",
       "      <th>01:00</th>\n",
       "      <th>01:30</th>\n",
       "      <th>02:00</th>\n",
       "      <th>02:30</th>\n",
       "      <th>03:00</th>\n",
       "      <th>03:30</th>\n",
       "      <th>04:00</th>\n",
       "      <th>...</th>\n",
       "      <th>19:00</th>\n",
       "      <th>19:30</th>\n",
       "      <th>20:00</th>\n",
       "      <th>20:30</th>\n",
       "      <th>21:00</th>\n",
       "      <th>21:30</th>\n",
       "      <th>22:00</th>\n",
       "      <th>22:30</th>\n",
       "      <th>23:00</th>\n",
       "      <th>23:30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1671764</td>\n",
       "      <td>0.652468</td>\n",
       "      <td>0.578830</td>\n",
       "      <td>0.558370</td>\n",
       "      <td>0.533940</td>\n",
       "      <td>0.502447</td>\n",
       "      <td>0.458478</td>\n",
       "      <td>0.416876</td>\n",
       "      <td>0.380274</td>\n",
       "      <td>0.349524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683978</td>\n",
       "      <td>0.696962</td>\n",
       "      <td>0.695705</td>\n",
       "      <td>0.695945</td>\n",
       "      <td>0.687557</td>\n",
       "      <td>0.683196</td>\n",
       "      <td>0.683839</td>\n",
       "      <td>0.679963</td>\n",
       "      <td>0.674628</td>\n",
       "      <td>0.667779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1340690</td>\n",
       "      <td>0.229885</td>\n",
       "      <td>0.222180</td>\n",
       "      <td>0.217988</td>\n",
       "      <td>0.214288</td>\n",
       "      <td>0.213922</td>\n",
       "      <td>0.221483</td>\n",
       "      <td>0.231873</td>\n",
       "      <td>0.245592</td>\n",
       "      <td>0.258329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372741</td>\n",
       "      <td>0.346652</td>\n",
       "      <td>0.325896</td>\n",
       "      <td>0.310921</td>\n",
       "      <td>0.294268</td>\n",
       "      <td>0.280191</td>\n",
       "      <td>0.267372</td>\n",
       "      <td>0.258394</td>\n",
       "      <td>0.248219</td>\n",
       "      <td>0.239698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000852</td>\n",
       "      <td>0.716705</td>\n",
       "      <td>0.693542</td>\n",
       "      <td>0.675252</td>\n",
       "      <td>0.654542</td>\n",
       "      <td>0.651702</td>\n",
       "      <td>0.649637</td>\n",
       "      <td>0.648813</td>\n",
       "      <td>0.672937</td>\n",
       "      <td>0.682930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379121</td>\n",
       "      <td>0.370730</td>\n",
       "      <td>0.360715</td>\n",
       "      <td>0.345218</td>\n",
       "      <td>0.339026</td>\n",
       "      <td>0.355087</td>\n",
       "      <td>0.389862</td>\n",
       "      <td>0.574275</td>\n",
       "      <td>0.719960</td>\n",
       "      <td>0.718757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90001517</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018420</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.002542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1815106</td>\n",
       "      <td>0.034713</td>\n",
       "      <td>0.033583</td>\n",
       "      <td>0.033790</td>\n",
       "      <td>0.033628</td>\n",
       "      <td>0.033465</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.033247</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.033095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034177</td>\n",
       "      <td>0.033954</td>\n",
       "      <td>0.034183</td>\n",
       "      <td>0.034223</td>\n",
       "      <td>0.034253</td>\n",
       "      <td>0.034158</td>\n",
       "      <td>0.033854</td>\n",
       "      <td>0.033893</td>\n",
       "      <td>0.034498</td>\n",
       "      <td>0.034512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>SIGMAPLAST</td>\n",
       "      <td>0.723962</td>\n",
       "      <td>0.695278</td>\n",
       "      <td>0.696736</td>\n",
       "      <td>0.694418</td>\n",
       "      <td>0.695502</td>\n",
       "      <td>0.693208</td>\n",
       "      <td>0.692603</td>\n",
       "      <td>0.692475</td>\n",
       "      <td>0.693352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638462</td>\n",
       "      <td>0.627162</td>\n",
       "      <td>0.656135</td>\n",
       "      <td>0.666052</td>\n",
       "      <td>0.672535</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>0.719468</td>\n",
       "      <td>0.720108</td>\n",
       "      <td>0.719691</td>\n",
       "      <td>0.719461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>SINTOFIL</td>\n",
       "      <td>0.613444</td>\n",
       "      <td>0.528363</td>\n",
       "      <td>0.527601</td>\n",
       "      <td>0.526592</td>\n",
       "      <td>0.525030</td>\n",
       "      <td>0.523573</td>\n",
       "      <td>0.521665</td>\n",
       "      <td>0.518018</td>\n",
       "      <td>0.512443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613016</td>\n",
       "      <td>0.617259</td>\n",
       "      <td>0.617420</td>\n",
       "      <td>0.616574</td>\n",
       "      <td>0.615983</td>\n",
       "      <td>0.616780</td>\n",
       "      <td>0.614077</td>\n",
       "      <td>0.607881</td>\n",
       "      <td>0.601575</td>\n",
       "      <td>0.608928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>SOCIEDAD INDUSTRIAL RELI  CYRANO</td>\n",
       "      <td>0.522447</td>\n",
       "      <td>0.533413</td>\n",
       "      <td>0.594090</td>\n",
       "      <td>0.619295</td>\n",
       "      <td>0.542844</td>\n",
       "      <td>0.474003</td>\n",
       "      <td>0.453784</td>\n",
       "      <td>0.474405</td>\n",
       "      <td>0.424981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228917</td>\n",
       "      <td>0.220160</td>\n",
       "      <td>0.220309</td>\n",
       "      <td>0.217405</td>\n",
       "      <td>0.226077</td>\n",
       "      <td>0.253856</td>\n",
       "      <td>0.331315</td>\n",
       "      <td>0.413486</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.534456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>TEXTILES TEXSA</td>\n",
       "      <td>0.675463</td>\n",
       "      <td>0.596102</td>\n",
       "      <td>0.601228</td>\n",
       "      <td>0.594504</td>\n",
       "      <td>0.587015</td>\n",
       "      <td>0.566832</td>\n",
       "      <td>0.579295</td>\n",
       "      <td>0.588318</td>\n",
       "      <td>0.574999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538375</td>\n",
       "      <td>0.606685</td>\n",
       "      <td>0.606651</td>\n",
       "      <td>0.577992</td>\n",
       "      <td>0.615831</td>\n",
       "      <td>0.665055</td>\n",
       "      <td>0.668014</td>\n",
       "      <td>0.661269</td>\n",
       "      <td>0.662274</td>\n",
       "      <td>0.675761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>VICUNHA ECUADOR</td>\n",
       "      <td>0.052938</td>\n",
       "      <td>0.043298</td>\n",
       "      <td>0.044413</td>\n",
       "      <td>0.044223</td>\n",
       "      <td>0.044250</td>\n",
       "      <td>0.044889</td>\n",
       "      <td>0.046489</td>\n",
       "      <td>0.046407</td>\n",
       "      <td>0.046141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057890</td>\n",
       "      <td>0.058319</td>\n",
       "      <td>0.059276</td>\n",
       "      <td>0.059634</td>\n",
       "      <td>0.058765</td>\n",
       "      <td>0.058191</td>\n",
       "      <td>0.054252</td>\n",
       "      <td>0.050815</td>\n",
       "      <td>0.054959</td>\n",
       "      <td>0.055723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Cliente     00:00     00:30     01:00     01:30  \\\n",
       "0                             1671764  0.652468  0.578830  0.558370  0.533940   \n",
       "1                             1340690  0.229885  0.222180  0.217988  0.214288   \n",
       "2                            90000852  0.716705  0.693542  0.675252  0.654542   \n",
       "3                            90001517  0.002208  0.001958  0.002012  0.001969   \n",
       "4                             1815106  0.034713  0.033583  0.033790  0.033628   \n",
       "..                                ...       ...       ...       ...       ...   \n",
       "384                        SIGMAPLAST  0.723962  0.695278  0.696736  0.694418   \n",
       "385                          SINTOFIL  0.613444  0.528363  0.527601  0.526592   \n",
       "386  SOCIEDAD INDUSTRIAL RELI  CYRANO  0.522447  0.533413  0.594090  0.619295   \n",
       "387                    TEXTILES TEXSA  0.675463  0.596102  0.601228  0.594504   \n",
       "388                   VICUNHA ECUADOR  0.052938  0.043298  0.044413  0.044223   \n",
       "\n",
       "        02:00     02:30     03:00     03:30     04:00  ...     19:00  \\\n",
       "0    0.502447  0.458478  0.416876  0.380274  0.349524  ...  0.683978   \n",
       "1    0.213922  0.221483  0.231873  0.245592  0.258329  ...  0.372741   \n",
       "2    0.651702  0.649637  0.648813  0.672937  0.682930  ...  0.379121   \n",
       "3    0.001885  0.002041  0.001962  0.001931  0.001952  ...  0.018420   \n",
       "4    0.033465  0.033268  0.033247  0.033200  0.033095  ...  0.034177   \n",
       "..        ...       ...       ...       ...       ...  ...       ...   \n",
       "384  0.695502  0.693208  0.692603  0.692475  0.693352  ...  0.638462   \n",
       "385  0.525030  0.523573  0.521665  0.518018  0.512443  ...  0.613016   \n",
       "386  0.542844  0.474003  0.453784  0.474405  0.424981  ...  0.228917   \n",
       "387  0.587015  0.566832  0.579295  0.588318  0.574999  ...  0.538375   \n",
       "388  0.044250  0.044889  0.046489  0.046407  0.046141  ...  0.057890   \n",
       "\n",
       "        19:30     20:00     20:30     21:00     21:30     22:00     22:30  \\\n",
       "0    0.696962  0.695705  0.695945  0.687557  0.683196  0.683839  0.679963   \n",
       "1    0.346652  0.325896  0.310921  0.294268  0.280191  0.267372  0.258394   \n",
       "2    0.370730  0.360715  0.345218  0.339026  0.355087  0.389862  0.574275   \n",
       "3    0.013992  0.010693  0.007931  0.006308  0.005220  0.003349  0.003003   \n",
       "4    0.033954  0.034183  0.034223  0.034253  0.034158  0.033854  0.033893   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "384  0.627162  0.656135  0.666052  0.672535  0.702778  0.719468  0.720108   \n",
       "385  0.617259  0.617420  0.616574  0.615983  0.616780  0.614077  0.607881   \n",
       "386  0.220160  0.220309  0.217405  0.226077  0.253856  0.331315  0.413486   \n",
       "387  0.606685  0.606651  0.577992  0.615831  0.665055  0.668014  0.661269   \n",
       "388  0.058319  0.059276  0.059634  0.058765  0.058191  0.054252  0.050815   \n",
       "\n",
       "        23:00     23:30  \n",
       "0    0.674628  0.667779  \n",
       "1    0.248219  0.239698  \n",
       "2    0.719960  0.718757  \n",
       "3    0.002486  0.002542  \n",
       "4    0.034498  0.034512  \n",
       "..        ...       ...  \n",
       "384  0.719691  0.719461  \n",
       "385  0.601575  0.608928  \n",
       "386  0.496200  0.534456  \n",
       "387  0.662274  0.675761  \n",
       "388  0.054959  0.055723  \n",
       "\n",
       "[389 rows x 49 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_registros_todas_las_curvas = pd.DataFrame(registros_curvas_todas)\n",
    "df_registros_todas_las_curvas.columns = columnas_df_todas_las_curvas\n",
    "df_registros_todas_las_curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_registros_todas_las_curvas.to_csv(f\"archivos_salida_script/datos_curvaas_tipo_30m_clientes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_registros_todas_las_curvas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mdf_registros_todas_las_curvas\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m registros_curvas_todas\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_registros_todas_las_curvas' is not defined"
     ]
    }
   ],
   "source": [
    "del df_registros_todas_las_curvas\n",
    "del registros_curvas_todas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 49)\n"
     ]
    }
   ],
   "source": [
    "df_registros_curvas = pd.read_csv(\"archivos_salida_script/datos_curvaas_tipo_30m_clientes.csv\", dtype={\"Cliente\": str})\n",
    "print(df_registros_curvas.shape)\n",
    "excluir = ['90000662',\n",
    "           '090000664']\n",
    "df_registros_curvas = df_registros_curvas[~df_registros_curvas[\"Cliente\"].isin(excluir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 49)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_registros_curvas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_registros_curvas.to_csv(\"archivos_salida_script/limpio_datos_curvas_tipo_30m_clientes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = df_registros_curvas.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387, 48)\n"
     ]
    }
   ],
   "source": [
    "print(curves.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(curves))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
