1.3. Alcance
Como se mencionó en la descripción del componente, el presente trabajo está
enmarcado en el análisis y segmentación de clientes no regulados del sector eléc-
trico, a partir de la construcción de sus curvas de carga características y la posterior
aplicación de algoritmos de aprendizaje no supervisado con el fin de identificar pa-
trones de consumo energético. El alcance de este trabajo está definido bajo las
siguientes consideraciones:
1. Se ha adoptado la metodología CRISP-DM como marco de referencia, con
una adaptación en su fase final. Dicha fase implica originalmente el desplie-
gue del modelo en un entorno productivo, pero en este trabajo va a enfocarse
en la evaluación comparativa de los resultados obtenidos con diferentes al-
goritmos de clustering, donde se presentarán métricas cuantitativas así como
visualizaciones interpretativas de las agrupaciones.
2. Se llevará a cabo un proceso ETL (Extracción, Transformación y Carga), el
cual obtiene, integra, limpia y normaliza los registros históricos de consumo
energético que se tienen de cada cliente, con la finalidad de generar curvas
de carga que representen el comportamiento energético de cada cliente. Este
proceso contempla la interpolación de valores nulos, la exclusión de días no
laborales, corrección de formatos inconsistentes y la normalización mediante
técnicas de escalamiento.
3. Se realizará la optimización e implementación de varios algoritmos de clus-
tering (KMeans, GaussianMixture, Birch y Spectral Clustering), estos fueron
seleccionados en función de su relevancia en la literatura y su aplicabilidad en
el análisis de análisis de curvas de carga. Para determinar el número óptimo
de agrupaciones se hara uso de métodos de validación como el método del
codo. Por otro lado, para la optimización de estos algoritmos se utilizará la co-
rrelación intra-cluster, esta métrica es la más adecuada pues captura de mejor
manera la similitud en forma de las curvas agrupadas.
4. Los resultados incluirán la curva de carga representativa de cada cliente, la
curva de carga correspondiente al día de máxima demanda, archivos .csv con
las coordenadas de dichas curvas. Asimismo, se presentarán resultados vi-
suales de los clústeres y una tabla comparativa con métricas que cuantifican
la calidad de las agrupaciones generadas por cada algoritmo.
5. Para el desarrollo del presente componente se ha contemplado Python como
lenguaje de programación de alto nivel, Visual Studio Code como entorno de
desarrollo integrado, bibliotecas especializadas en análisis de datos y machine
learning (pandas, scikit-learn, numpy, matplotlib, entre otras), así como herra-
mientas de orquestación, en este caso Apache Airflow sobre Docker, para la
automatización del proceso ETL.
Por lo anterior expuesto el alcance del componente se limita a la construcción,
aplicación y evaluación de modelos de clustering basados en la similitud de curvas
de carga, sin abordar fases posteriores como despliegues productivos en entornos
de la empresa distribuidora de energía