{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notas del cuaderno de trabajo\n",
    "\n",
    "El presente cuaderno de trabajo realiza casi lo mismo que el cuaderno 'clasificación_clientes.ipynb', con una sutiles diferencias:\n",
    "- El presente cuaderno de trabajo normaliza cada día individualmente, con el fin de que días anómalos no aplanen los demas días (antes se normalizaba directamente los datos de todo el año)\n",
    "- Ahora se usa la mediana para generar la curva tipo de cada cliente (es más resistente a valores atípicos)\n",
    "\n",
    "Se ha implementado una función que genera todas las gráficas de curvas de todos los 'n' días que tiene un cliente, debido a que para cada cliente este proceso toma aproximadamente 80s, se ha decidido realizarlo solo para 20 clientes seleccionados:\n",
    "Tenía pensado realizarlo para los siguientes clientes:\n",
    "- 12\n",
    "- 1234002\n",
    "- 1457182\n",
    "- 1627579\n",
    "- 10020880\n",
    "- 90000503\n",
    "- 90001202\n",
    "- TEXTILES TEXSA\n",
    "- GC NOVOPAN DEL ECUADOR\n",
    "- FLEXIPLAST\n",
    "- ECOFROZ\n",
    "- IDEAL ALAMBREC\n",
    "- LOS COCOS\n",
    "- PLANTA PANIFICADORA\n",
    "- PRINTOPAC\n",
    "\n",
    "En forma de array para copiar en código:\n",
    " - arr_clientes_graf = ['12', '1234002', '1457182', '1627579', '10020880', '90000503', '90001202', 'TEXTILES TEXSA', 'GC NOVOPAN DEL ECUADOR', 'FLEXIPLAST', 'ECOFROZ', 'IDEAL ALAMBREC', 'LOS COCOS', 'PLANTA PANIFICADORA', 'PRINTOPAC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "mmscaler = MinMaxScaler()\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para leer archivos .csv con diversos formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intentar_abrir_archivo_datos(path_archivo):\n",
    "\n",
    "    df_archivo_telem_tab = pd.DataFrame([1,2,3], columns=[\"prueba\"])\n",
    "    df_archivo_telem_pc = pd.DataFrame([1,2,3], columns=[\"prueba\"])\n",
    "    df_archivo_telem_c = pd.DataFrame([1,2,3], columns=[\"prueba\"])\n",
    "\n",
    "    # Intentar leer el archivo con separador 'tab'\n",
    "    try:\n",
    "        #print(\"Leyendo con tab\")\n",
    "        df_archivo_telem_tab = pd.read_csv(path_archivo,\n",
    "                                            sep=\"\\t\",\n",
    "                                            #decimal=\",\",\n",
    "                                            skiprows=11,\n",
    "                                            #na_values=\"N/D\",\n",
    "                                            encoding=\"utf-16\",\n",
    "                                            #on_bad_lines=\"skip\",\n",
    "                                            encoding_errors=\"ignore\" \n",
    "                                            ) \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Intentar leer el archivo con separador 'punto y coma'\n",
    "    try:\n",
    "        #print(\"Leyendo con ;\")\n",
    "        df_archivo_telem_pc = pd.read_csv(path_archivo,\n",
    "                                            sep=\";\",\n",
    "                                            #decimal=\",\",\n",
    "                                            skiprows=11,\n",
    "                                            #na_values=\"N/D\",\n",
    "                                            #encoding=\"utf-16\",\n",
    "                                            #on_bad_lines=\"skip\",\n",
    "                                            encoding_errors=\"ignore\" \n",
    "                                            )\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Intentar leer el archivo con separador 'coma'\n",
    "    try:\n",
    "        #print(\"Leyendo con ,\")\n",
    "        df_archivo_telem_c = pd.read_csv(path_archivo,\n",
    "                                            sep=\",\",\n",
    "                                            #decimal=\",\",\n",
    "                                            skiprows=11,\n",
    "                                            #na_values=\"N/D\",\n",
    "                                            #encoding=\"utf-16\",\n",
    "                                            #on_bad_lines=\"skip\",\n",
    "                                            encoding_errors=\"ignore\" \n",
    "                                            )\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    if len(df_archivo_telem_tab.columns) > 1:\n",
    "        df_archivo_telem = df_archivo_telem_tab.copy()\n",
    "    elif len(df_archivo_telem_pc.columns) > 1:\n",
    "        df_archivo_telem = df_archivo_telem_pc.copy()\n",
    "    else:\n",
    "        df_archivo_telem = df_archivo_telem_c.copy()\n",
    "\n",
    "    return df_archivo_telem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extracción de los archivos de cada grupo de clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Extracción de los archivos con las mediciones mensuales del primer grupo de clientes\n",
    "\n",
    "Estos clientes están clasificados por CUEN, y el formato de sus archivos varían, el procedimiento a seguir será:\n",
    "1. Iterar sobre cada código de cliente\n",
    "2. Buscar sus archivos de datos mensuales\n",
    "3. Unificar todos en un solo archivo\n",
    "4. El identificador a usar es el código de cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediciones_clientes_g1 = r\"../data/mediciones_por_mes_g1\"\n",
    "archivos_mediciones_g1 = list(os.scandir(mediciones_clientes_g1))\n",
    "columnas_extraer_g1 = [\"Fecha\",\"Demanda activa DEL\",\"Demanda reactiva DEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes único encontrados en la carpeta de mediciones del grupo uno: 314\n"
     ]
    }
   ],
   "source": [
    "clientes_unicos_g1 = set()\n",
    "\n",
    "for medicion in archivos_mediciones_g1:\n",
    "    cliente = medicion.name.split('-')[1]\n",
    "    clientes_unicos_g1.add(cliente)\n",
    "\n",
    "print(f\"Clientes único encontrados en la carpeta de mediciones del grupo uno: {len(clientes_unicos_g1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando clientes del grupo 01: 100%|██████████| 314/314 [00:43<00:00,  7.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar los clientes con sus respectivos datos\n",
    "dict_dfs_clientes_g1 = {}\n",
    "\n",
    "# Iterar sobre cada cliente\n",
    "for cliente in tqdm(clientes_unicos_g1, desc=\"Procesando clientes del grupo 01\"):\n",
    "    datos_cliente = []\n",
    "    # Iterar sobre cada archivo de medicion del grupo 01\n",
    "    for medicion in archivos_mediciones_g1:\n",
    "        if cliente == medicion.name.split(\"-\")[1]:\n",
    "            df_cliente = intentar_abrir_archivo_datos(f\"{mediciones_clientes_g1}/{medicion.name}\")\n",
    "            datos_cliente.extend(df_cliente[columnas_extraer_g1].values)\n",
    "\n",
    "    # Convertir a DataFrame los datos concatenados\n",
    "    df_datos_anual_cliente = pd.DataFrame(datos_cliente, columns=columnas_extraer_g1)\n",
    "    \n",
    "    # Almacenar en el diccionario (Clave->Cliente   Valor->DataFrame)\n",
    "    dict_dfs_clientes_g1[cliente]=df_datos_anual_cliente\n",
    "    \n",
    "    # Eliminar dataframe concatenado para liberar memoria\n",
    "    del df_datos_anual_cliente\n",
    "    #df_datos_anual_cliente.to_csv(f\"mediciones_por_anio/g1_perfil_carga_anual-{cliente}-2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Extracción de los archivos con las mediciones mensuales del segundo grupo de clientes\n",
    "\n",
    "De estos clientes tenemos carpetas con sus mediciones por mes, no existe tabla de excel inicial, se procederá a realizar lo siguiente:\n",
    "1. Iterar sobre cada carpeta (cliente)\n",
    "2. Obtener los datos de sus 12 meses\n",
    "3. Unificar en un único archivo anual\n",
    "4. Se usará el nombre del cliente como identificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediciones_clientes_g2 = \"../data/mediciones_por_mes_g2\"\n",
    "archivos_mediciones_g2 = list(os.scandir(mediciones_clientes_g2))\n",
    "columnas_extraer_g2 = [\"Fecha\", \"AS (kWh)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes único encontrados en la carpeta de mediciones del grupo uno: 75\n"
     ]
    }
   ],
   "source": [
    "print(f\"Clientes único encontrados en la carpeta de mediciones del grupo uno: {len(archivos_mediciones_g2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando clientes del grupo 02: 100%|██████████| 75/75 [00:05<00:00, 13.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar los clientes con sus datos\n",
    "dict_dfs_clientes_g2 = {}\n",
    "\n",
    "# Iterar sobre cada cliente\n",
    "for archivos_cliente in tqdm(archivos_mediciones_g2, desc=\"Procesando clientes del grupo 02\"):\n",
    "    nombre_cli = archivos_cliente.name.strip()\n",
    "    df_concat = pd.DataFrame()\n",
    "\n",
    "    # Obtener los archivos de las mediciones mensuales del cliente\n",
    "    mediciones_mensuales_cliente = os.scandir(rf\"{mediciones_clientes_g2}/{nombre_cli}\")\n",
    "\n",
    "    for medicion in mediciones_mensuales_cliente:\n",
    "        medicion_mensual = pd.read_csv(rf\"{mediciones_clientes_g2}/{nombre_cli}/{medicion.name}\", sep=\";\", skiprows=2, encoding='ISO-8859-1')\n",
    "        medicion_mensual = medicion_mensual[columnas_extraer_g2]\n",
    "        df_concat = pd.concat([df_concat, medicion_mensual])\n",
    "\n",
    "    # Almacenar en el diccionario (Clave->Cliente   Valor->DataFrame)\n",
    "    dict_dfs_clientes_g2[nombre_cli] = df_concat\n",
    "    \n",
    "    # Eliminar dataframe concatenado para liberar memoria\n",
    "    del df_concat\n",
    "    #df_concat.to_csv(rf\"mediciones_por_anio/g2_perfil_carga_anual-{nombre_cli}-2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocesamiento de los datos\n",
    "\n",
    "Ahora tenemos todos los datos unificados anualmente por cada cliente, tenemos que limpiar y preprocesar, realizar las siguientes tareas:\n",
    "1. Calcular la potencia aparente (resultado de aplicar teorema pitágoras sobre potencia activa y reactiva)\n",
    "2. Separar la columna 'fecha' en dos columnas 'fecha' y 'hora', fecha va a tener formato 'año/mes/dia' y hora el formato 'hh:mm'\n",
    "3. Excluir aquellos registros que correspondan a fechas de sábado, domingo o días de feriado nacional\n",
    "4. Normalizar los datos para que todos estén en la misma escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
      "DatetimeIndex(['2023-07-02', '2023-02-20', '2023-02-21', '2023-04-07',\n",
      "               '2023-05-01', '2023-05-26', '2023-08-11', '2023-10-09',\n",
      "               '2023-10-02', '2023-10-03', '2023-12-25'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "feriados_nacionales = [\"2/7/2023\", \"20/2/2023\", \"21/2/2023\", \"7/4/2023\", \"1/5/2023\", \\\n",
    "                       \"26/5/2023\", \"11/8/2023\", \"9/10/2023\", \"2/10/2023\", \"3/10/2023\", \"25/12/2023\"]\n",
    "feriados_nacionales = pd.to_datetime(feriados_nacionales, format='%d/%m/%Y')\n",
    "\n",
    "dict_meses = {\"01\": \"Enero\",\n",
    "              \"02\": \"Febrero\",\n",
    "              \"03\": \"Marzo\",\n",
    "              \"04\": \"Abril\",\n",
    "              \"05\": \"Mayo\",\n",
    "              \"06\": \"Junio\",\n",
    "              \"07\": \"Julio\",\n",
    "              \"08\": \"Agosto\",\n",
    "              \"09\": \"Septiembre\",\n",
    "              \"10\": \"Octubre\",\n",
    "              \"11\": \"Noviembre\",\n",
    "              \"12\": \"Diciembre\"}\n",
    "\n",
    "print(list(dict_meses.keys()))\n",
    "print(feriados_nacionales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fecha_formato_unico(fecha_str):\n",
    "\n",
    "    # Poner separador único el '/' y año únicamente 2023\n",
    "    fecha_str = fecha_str.replace('-','/').replace('2024','2023')\n",
    "\n",
    "    if len(fecha_str.split('/')[0]) == 4: # Cuando el formato es año/mes/día\n",
    "        return fecha_str\n",
    "    elif len(fecha_str.split('/')[0]) != 4: # Cuando el formato es día/mes/año\n",
    "        seps = fecha_str.split('/')\n",
    "        return f\"{seps[-1]}/{seps[1]}/{seps[0]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 - Transformación columna fecha archivos anuales grupo 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dfs_procesados_g1 = {}\n",
    "\n",
    "for cliente, df_archivo_g1 in dict_dfs_clientes_g1.items():\n",
    "\n",
    "    # Transformar columna fecha a cadena\n",
    "    df_archivo_g1[\"Fecha\"] = df_archivo_g1[\"Fecha\"].astype(\"string\")\n",
    "\n",
    "    # Eliminar los valores nulos en la columna 'Fecha'\n",
    "    df_archivo_g1 = df_archivo_g1.dropna(subset=\"Fecha\")\n",
    "\n",
    "    # Separar para obtener columna Hora\n",
    "    df_archivo_g1[\"Hora\"] = df_archivo_g1[\"Fecha\"].apply(lambda x: x.split()[1].strip())\n",
    "\n",
    "    # Separar para obtener columna Fecha\n",
    "    df_archivo_g1[\"Fecha\"] = df_archivo_g1[\"Fecha\"].apply(lambda x: x.split()[0].strip())\n",
    "\n",
    "    # Transformar la columna Fecha a un formato único\n",
    "    df_archivo_g1[\"Fecha\"] = df_archivo_g1[\"Fecha\"].apply(fecha_formato_unico)\n",
    "\n",
    "    # Debido a que a veces se ponen datos del 2024 para reemplazar los faltantes del 2023\n",
    "    # debemos descartar la fecha 29 de febrero, pues en 2023 no existe\n",
    "    df_archivo_g1 = df_archivo_g1[df_archivo_g1[\"Fecha\"] != \"2023/02/29\"]\n",
    "    \n",
    "    # Eliminar duplicados y conservar el original del 2023\n",
    "    df_archivo_g1[\"Fecha-Hora\"] = df_archivo_g1[\"Fecha\"] + \" \" + df_archivo_g1[\"Hora\"]\n",
    "    df_archivo_g1 = df_archivo_g1.drop_duplicates(subset=\"Fecha-Hora\", keep=\"first\")\n",
    "\n",
    "    # Transformar columna Fecha a datetime\n",
    "    df_archivo_g1[\"Fecha\"] = pd.to_datetime(df_archivo_g1[\"Fecha\"], format='%Y/%m/%d')\n",
    "\n",
    "    # Obtener la potencia aparente\n",
    "    df_archivo_g1[\"Potencia_aparente\"] = np.sqrt((df_archivo_g1[\"Demanda activa DEL\"]**2) + (df_archivo_g1[\"Demanda reactiva DEL\"]**2))\n",
    "\n",
    "    # Eliminar días feriados y días de fin de semana\n",
    "    df_archivo_g1 = df_archivo_g1[~df_archivo_g1['Fecha'].isin(feriados_nacionales) & ~df_archivo_g1['Fecha'].dt.weekday.isin([5, 6])]\n",
    "\n",
    "    # Interpolar valores nulos usando una función polinomial\n",
    "    df_archivo_g1[\"Potencia_aparente\"] = df_archivo_g1[\"Potencia_aparente\"].interpolate(method='spline', order=3)\n",
    "\n",
    "    # Conservar solo las columnas de interés\n",
    "    df_archivo_g1 = df_archivo_g1[[\"Fecha\", \"Hora\", \"Potencia_aparente\"]]\n",
    "\n",
    "    # Escalar las mediciones (cada día se escala individualmente)\n",
    "    df_archivo_g1[\"Potencia_aparente_escalada\"] = df_archivo_g1.groupby(\"Fecha\")[\"Potencia_aparente\"].transform(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min()) if (x.max() - x.min()) != 0 else 0\n",
    "    )\n",
    "\n",
    "    # Guardar en un nuevo diccionario los datos procesados\n",
    "    dict_dfs_procesados_g1[cliente] = df_archivo_g1\n",
    "    \n",
    "    # Liberar memoria\n",
    "    del df_archivo_g1\n",
    "    \n",
    "#del dict_dfs_clientes_g1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 - Transformación columna fecha archivos anuales grupo 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dfs_procesados_g2 = {}\n",
    "\n",
    "for cliente, df_archivo_g2 in dict_dfs_clientes_g2.items():\n",
    "\n",
    "    # Transformar columna fecha a cadena\n",
    "    df_archivo_g2[\"Fecha\"] = df_archivo_g2[\"Fecha\"].astype(\"string\")\n",
    "\n",
    "    # Eliminar registros que contienen el total\n",
    "    df_archivo_g2 = df_archivo_g2[~df_archivo_g2[\"Fecha\"].str.contains(\"Total\")]\n",
    "\n",
    "    # Eliminar los valores nulos en la columna 'Fecha'\n",
    "    df_archivo_g2 = df_archivo_g2.dropna(subset=\"Fecha\")\n",
    "\n",
    "    # Separar para obtener columna Hora\n",
    "    df_archivo_g2[\"Hora\"] = df_archivo_g2[\"Fecha\"].apply(lambda x: x.split()[1].strip())\n",
    "\n",
    "    # Separar para obtener columna Fecha\n",
    "    df_archivo_g2[\"Fecha\"] = df_archivo_g2[\"Fecha\"].apply(lambda x: x.split()[0].strip())\n",
    "\n",
    "    # Eliminar duplicados y conservar el original del 2023\n",
    "    df_archivo_g2[\"Fecha-Hora\"] = df_archivo_g2[\"Fecha\"] + \" \" + df_archivo_g2[\"Hora\"]\n",
    "    df_archivo_g2[\"Fecha-Hora\"] = pd.to_datetime(df_archivo_g2[\"Fecha-Hora\"], yearfirst=True)\n",
    "    df_archivo_g2 = df_archivo_g2.drop_duplicates(subset=\"Fecha-Hora\", keep=\"first\")\n",
    "\n",
    "    # Restar un timedelta de 15 a todas las fechas (Solo en este caso por que la ultima fecha)\n",
    "    # se pasa al siguiente mes\n",
    "    df_archivo_g2[\"Fecha-Hora\"] = df_archivo_g2[\"Fecha-Hora\"] - pd.Timedelta(minutes=15)\n",
    "\n",
    "    # Separar nuevamente para obtener columna Hora\n",
    "    df_archivo_g2[\"Hora\"] = df_archivo_g2[\"Fecha-Hora\"].astype(\"string\").apply(lambda x: x.split()[1][:-3].strip())\n",
    "\n",
    "    # Separar nuevamente para obtener columna Fecha\n",
    "    df_archivo_g2[\"Fecha\"] = df_archivo_g2[\"Fecha-Hora\"].astype(\"string\").apply(lambda x: x.split()[0].strip())\n",
    "\n",
    "    # Transformar la columna Fecha a un formato único\n",
    "    df_archivo_g2[\"Fecha\"] = df_archivo_g2[\"Fecha\"].apply(fecha_formato_unico)\n",
    "\n",
    "    # Debido a que a veces se ponen datos del 2024 para reemplazar los faltantes del 2023\n",
    "    # debemos descartar la fecha 29 de febrero, pues en 2023 no existe\n",
    "    df_archivo_g2 = df_archivo_g2[df_archivo_g2[\"Fecha\"] != \"2023/02/29\"]\n",
    "\n",
    "    # Transformar columna Fecha a datetime\n",
    "    df_archivo_g2[\"Fecha\"] = pd.to_datetime(df_archivo_g2[\"Fecha\"], format='%Y/%m/%d')\n",
    "\n",
    "    # Limpiar la columna 'SE (KVah)'\n",
    "    df_archivo_g2[\"AS (kWh)\"] = df_archivo_g2[\"AS (kWh)\"].astype(\"string\").str.replace(\",\", \"\").replace('\"','')\n",
    "    df_archivo_g2[\"AS (kWh)\"] = df_archivo_g2[\"AS (kWh)\"].astype(\"float\")\n",
    "\n",
    "    # Obtener la potencia aparente\n",
    "    df_archivo_g2[\"Potencia_aparente\"] = df_archivo_g2[\"AS (kWh)\"] * 4\n",
    "\n",
    "    # Eliminar días feriados y días de fin de semana\n",
    "    df_archivo_g2 = df_archivo_g2[~df_archivo_g2['Fecha'].isin(feriados_nacionales) & ~df_archivo_g2['Fecha'].dt.weekday.isin([5, 6])]\n",
    "\n",
    "    # Interpolar valores nulos usando una función polinomial\n",
    "    df_archivo_g2[\"Potencia_aparente\"] = df_archivo_g2[\"Potencia_aparente\"].interpolate(method='spline', order=3)\n",
    "\n",
    "    # Conservar solo las columnas de interés\n",
    "    df_archivo_g2 = df_archivo_g2[[\"Fecha\", \"Hora\", \"Potencia_aparente\"]]\n",
    "\n",
    "    # Escalar las mediciones (cada día se escala individualmente)\n",
    "    df_archivo_g2[\"Potencia_aparente_escalada\"] = df_archivo_g2.groupby(\"Fecha\")[\"Potencia_aparente\"].transform(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min()) if (x.max() - x.min()) != 0 else 0\n",
    "    )\n",
    "\n",
    "    # Guardar en un nuevo diccionario los datos procesados\n",
    "    dict_dfs_procesados_g2[cliente] = df_archivo_g2\n",
    "    \n",
    "    # Liberar memoria\n",
    "    del df_archivo_g2\n",
    "    \n",
    "#del dict_dfs_clientes_g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generación de los entregables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_coords_curva_tipo(df):\n",
    "\n",
    "    # Agrupar por hora y aplicar mediana\n",
    "    df_grouped = df.groupby(\"Hora\")[\"Potencia_aparente_escalada\"].apply(np.median).sort_index(ascending=True).reset_index(drop=False)\n",
    "\n",
    "    # Retornar el array con los 96 valores de demanda\n",
    "    return df_grouped\n",
    "\n",
    "def obtener_coords_dia_demanda_max(df):\n",
    "\n",
    "    # Obtener el máximo valor de potencia aparente\n",
    "    max_potencia = df['Potencia_aparente'].max()\n",
    "\n",
    "    # Encontrar la fecha correspondiente a la máxima potencia aparente\n",
    "    fecha_max_potencia = df[df['Potencia_aparente'] == max_potencia]['Fecha'].iloc[0]\n",
    "\n",
    "    # Filtrar los registros correspondientes a esa fecha\n",
    "    df_max_fecha = df[df['Fecha'] == fecha_max_potencia]\n",
    "\n",
    "    # Ordenar el resultado de manera ascendente por 'Hora'\n",
    "    df_max_fecha = df_max_fecha.sort_values(by=\"Hora\", ascending=True)\n",
    "\n",
    "    return fecha_max_potencia, df_max_fecha[[\"Hora\",\"Potencia_aparente_escalada\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_curva_tipo(df, cod_cli, path, path_ctipos):\n",
    "\n",
    "    # Generar el gráfico de la curva tipo\n",
    "    _ = plt.figure(figsize=(16, 6))\n",
    "    _ = plt.plot(df[\"Hora\"], df[\"Potencia_aparente_escalada\"], marker='o', color='b', linestyle='-', label='Potencia Aparente Escalada')\n",
    "    _ = plt.title(f'Curva tipo cliente {cod_cli}')\n",
    "    _ = plt.xlabel('Hora')\n",
    "    _ = plt.ylabel('Potencia Aparente Escalada')\n",
    "    _ = plt.grid(True)\n",
    "\n",
    "    # Rotar etiquetas para que no se vea acumulado el eje X\n",
    "    _ = plt.xticks(df[\"Hora\"].values[::2], rotation=45)\n",
    "\n",
    "    # Para que no se distorsione la dimenisión del eje Y\n",
    "    _ = plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "    # Evitar recortes en las etiquetas\n",
    "    _ = plt.tight_layout()\n",
    "\n",
    "    # Guardar la gráfica en un directorio\n",
    "    _ = plt.savefig(f\"{path}/curva_tipo_{cod_cli}.png\", format='png', dpi=150)  # Puedes cambiar el formato a 'jpg', 'pdf', etc.\n",
    "    _ = plt.savefig(f\"../outputs/{path_ctipos}/curva_tipo_{cod_cli}.png\", format='png', dpi=150)  # Puedes cambiar el formato a 'jpg', 'pdf', etc.\n",
    "    \n",
    "    # Cerrar la figura después de guardarla para liberar recursos\n",
    "    _ = plt.close()  \n",
    "\n",
    "def graficar_dia_max_demanda(df, cod_cli, path, fecha):\n",
    "\n",
    "    # Graficar la potencia aparente escalada a lo largo del día\n",
    "    _ = plt.figure(figsize=(16, 6))\n",
    "    _ = plt.plot(df[\"Hora\"], df[\"Potencia_aparente_escalada\"], marker='o', color='r', linestyle='-', label=f'Potencia Aparente Escalada')\n",
    "    _ = plt.title(f'Curva del día de demanda máxima {fecha} para cliente {cod_cli}')\n",
    "    _ = plt.xlabel('Hora')\n",
    "    _ = plt.ylabel('Potencia Aparente Escalada')\n",
    "    _ = plt.grid(True)\n",
    "    _ = plt.legend()\n",
    "\n",
    "    # Rotar etiquetas para que no se vea acumulado el eje X\n",
    "    _ = plt.xticks(df[\"Hora\"].values[::2], rotation=45)\n",
    "\n",
    "    # Para que no se distorsione la dimenisión del eje Y\n",
    "    _ = plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "    # Evitar recortes en las etiquetas\n",
    "    _ = plt.tight_layout()\n",
    "\n",
    "    # Guardar la gráfica en un archivo (por ejemplo, como archivo PNG)\n",
    "    _ = plt.savefig(f\"{path}/curva_dia_demanda_max_{cod_cli}.png\", format='png', dpi=150)  # Puedes cambiar el formato a 'jpg', 'pdf', etc.\n",
    "    \n",
    "    # Cerrar la figura después de guardarla para liberar recursos\n",
    "    _ = plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_horas(df, columna_hora=\"Hora\", columna_valor=\"Potencia_aparente_escalada\"):\n",
    "\n",
    "    # Convertir la columna Hora a tipo datetime\n",
    "    df[\"Hora\"] = pd.to_datetime(df[columna_hora], format=\"%H:%M\")\n",
    "\n",
    "    # Agrupar por hora y tomar el punto medio (hh:30)\n",
    "    df[\"Hora\"] = df[\"Hora\"].dt.floor(\"H\") + pd.Timedelta(minutes=30)\n",
    "\n",
    "    # Recortar a HH:MM\n",
    "    df[\"Hora\"] = df[\"Hora\"].astype(\"string\").apply(lambda x: x.split()[1][:-3])\n",
    "\n",
    "    # Agrupar por la nueva columna de hora y calcular el promedio de los valores\n",
    "    return df.groupby(\"Hora\")[columna_valor].apply(np.mean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_30_min(df, columna_hora=\"Hora\", columna_valor=\"Potencia_aparente_escalada\"):\n",
    "\n",
    "    # Convertir la columna Hora a tipo datetime\n",
    "    df[\"Hora\"] = pd.to_datetime(df[columna_hora], format=\"%H:%M\")\n",
    "\n",
    "    # Redondear hacia arriba al final del intervalo de 30 minutos\n",
    "    df[\"Hora\"] = df[\"Hora\"] + pd.Timedelta(minutes=30)\n",
    "    df[\"Hora\"] = df[\"Hora\"].dt.floor(\"H\") + (df[\"Hora\"].dt.minute // 30) * pd.Timedelta(minutes=30)\n",
    "\n",
    "    # Recortar a HH:MM\n",
    "    df[\"Hora\"] = df[\"Hora\"].astype(\"string\").apply(lambda x: x.split()[1][:-3])\n",
    "\n",
    "    # Agrupar por la nueva columna de hora y calcular el promedio de los valores\n",
    "    return df.groupby(\"Hora\")[columna_valor].apply(np.mean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_cliente(df, columna_potencia, carpeta_salida):\n",
    "    \"\"\"\n",
    "    Genera y guarda una gráfica por cada día para un cliente.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame con las columnas 'Fecha', 'Hora' y columna_potencia.\n",
    "    - columna_potencia: Nombre de la columna con los valores de potencia a graficar.\n",
    "    - carpeta_salida: Ruta de la carpeta donde se guardarán las gráficas.\n",
    "    \"\"\"\n",
    "    # Crear carpeta si no existe\n",
    "    os.makedirs(carpeta_salida, exist_ok=True)\n",
    "    \n",
    "    # Unir Fecha y Hora en un solo datetime\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Fecha\"].astype(\"string\") + \" \" + df[\"Hora\"])\n",
    "    \n",
    "    # Agrupar por día\n",
    "    df[\"Fecha\"] = pd.to_datetime(df[\"Fecha\"])\n",
    "    dias = df[\"Fecha\"].unique()\n",
    "\n",
    "    print(f\"Generando {len(dias)} gráficas en la carpeta '{carpeta_salida}'...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    for dia in dias:\n",
    "        df_dia = df[df[\"Fecha\"] == dia]\n",
    "        dia_semana = dia.strftime(\"%A\")  # Obtener el nombre del día (Monday, Tuesday, etc.)\n",
    "\n",
    "        # Crear figura\n",
    "        _ = plt.figure(figsize=(8, 4))\n",
    "        _ = plt.plot(df_dia[\"Hora\"], df_dia[columna_potencia], marker=\"o\", linestyle=\"-\")\n",
    "        _ = plt.title(f\"{dia_semana} - {dia.date()} Potencia Escalada\")\n",
    "        _ = plt.xlabel(\"Hora\")\n",
    "        _ = plt.ylabel(\"Potencia Escalada\")\n",
    "        _ = plt.xticks(df_dia[\"Hora\"].values[::4], rotation=45)\n",
    "        _ = plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        _ = plt.tight_layout()\n",
    "\n",
    "        # Guardar gráfico con día de la semana en el nombre\n",
    "        nombre_archivo = os.path.join(carpeta_salida, f\"{dia_semana}-{dia.date()}.png\")\n",
    "        _ = plt.savefig(nombre_archivo, dpi=100)\n",
    "        _ = plt.close()\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_tiempo = end_time - start_time\n",
    "    print(f\"✅ Gráficas generadas en {total_tiempo:.2f} segundos.\")\n",
    "\n",
    "    return total_tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso de agregación y obtención de las curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_entregables = \"../outputs\"\n",
    "\n",
    "dict_todos_los_clientes = dict_dfs_procesados_g1 | dict_dfs_procesados_g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_clientes_graf = ['12', '1234002', '1457182', '1627579', '10020880', '90000503', '90001202', 'TEXTILES TEXSA', 'GC NOVOPAN DEL ECUADOR', 'FLEXIPLAST', 'ECOFROZ', 'IDEAL ALAMBREC', 'LOS COCOS', 'PLANTA PANIFICADORA', 'PRINTOPAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpeta_todas_ctipos = 'curvas_diarias'\n",
    "carpeta_entregables = 'entregables_por_cliente_v2'\n",
    "carpeta_ctipos = 'curvas_tipo_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del dict_dfs_procesados_g1\n",
    "#del dict_dfs_procesados_g2\n",
    "\n",
    "registros_curvas_todas = []\n",
    "\n",
    "for cliente, df_medicion_anual in dict_todos_los_clientes.items():\n",
    "\n",
    "    # Lista para almacenar todos los valores de la curva tipo del cliente\n",
    "    registros_curva_cliente = []\n",
    "    \n",
    "    # Verificar si a ese cliente se le tienen que graficar todos los días\n",
    "    #if cliente in arr_clientes_graf:\n",
    "        #dir_dias_todos_cliente = fr\"{path_entregables}/{carpeta_todas_ctipos}/{cliente}\"\n",
    "        #graficar_cliente(df_medicion_anual, 'Potencia_aparente_escalada', dir_dias_todos_cliente)\n",
    "\n",
    "    # Crear el directorio para los entregables (Si no existe)\n",
    "    dir_entregables_cli = fr\"{path_entregables}/{carpeta_entregables}/{cliente}\"\n",
    "    os.makedirs(os.path.normpath(dir_entregables_cli), exist_ok=True)\n",
    "\n",
    "    # Crear el directorio para guardar únicamente las curvas tipo\n",
    "    dir_ctipos = fr\"{path_entregables}/{carpeta_ctipos}\"\n",
    "    os.makedirs(os.path.normpath(dir_ctipos), exist_ok=True)\n",
    "    \n",
    "    # Generar el archivo con los datos de la curva tipo\n",
    "    df_curva_tipo = obtener_coords_curva_tipo(df_medicion_anual)\n",
    "    #df_curva_tipo = agrupar_30_min(df_curva_tipo)\n",
    "    df_curva_tipo.to_csv(f\"{dir_entregables_cli}/datos_curva_tipo_{cliente}.csv\", index=False)\n",
    "\n",
    "    # Guardar los datos en una lista\n",
    "    registros_curva_cliente.append(cliente)\n",
    "    for valor in df_curva_tipo[\"Potencia_aparente_escalada\"].values:\n",
    "        registros_curva_cliente.append(valor)\n",
    "\n",
    "    # Generar el archivo con los datos de la curva del día que hubo la demanda máxima\n",
    "    fecha_max_dem, df_curva_dia_dem_max = obtener_coords_dia_demanda_max(df_medicion_anual)\n",
    "    df_curva_dia_dem_max = df_curva_dia_dem_max.sort_values(by=\"Hora\", ascending=True)\n",
    "    df_curva_dia_dem_max.to_csv(f\"{dir_entregables_cli}/datos_curva_dia_demanda_max.csv\", index=False)\n",
    "\n",
    "    # Generar la gráfica de la curva tipo\n",
    "    graficar_curva_tipo(df_curva_tipo, cliente, dir_entregables_cli, carpeta_ctipos)\n",
    "\n",
    "    # Generar la gráfica de la curva del día de demanda máxima\n",
    "    graficar_dia_max_demanda(df_curva_dia_dem_max, cliente, dir_entregables_cli, str(fecha_max_dem).split()[0])\n",
    "    \n",
    "    # Filtrar el DataFrame para ese día\n",
    "    df_dia_max = df_medicion_anual[df_medicion_anual[\"Fecha\"].dt.date == fecha_max_dem.date()]\n",
    "\n",
    "    # Generar un archivo plano con la demanda máximo y mínima\n",
    "    open(rf'{dir_entregables_cli}/Potencia_max_min.txt', 'w')\\\n",
    "        .write(f'Pot_aparente_max: {df_dia_max[\"Potencia_aparente\"].max()}\\nPot_aparente_min: {df_dia_max[\"Potencia_aparente\"].min()}')\n",
    "\n",
    "    # Guardar la lista con los registros de un cliente en otra lista\n",
    "    registros_curvas_todas.append(registros_curva_cliente)\n",
    "\n",
    "columnas_df_todas_las_curvas = [\"Cliente\"]\n",
    "columnas_df_todas_las_curvas.extend(df_curva_tipo[\"Hora\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cargar los datos a MongoDB (únicamente los de curvas tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dict_todos_los_clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cliente</th>\n",
       "      <th>00:00</th>\n",
       "      <th>00:15</th>\n",
       "      <th>00:30</th>\n",
       "      <th>00:45</th>\n",
       "      <th>01:00</th>\n",
       "      <th>01:15</th>\n",
       "      <th>01:30</th>\n",
       "      <th>01:45</th>\n",
       "      <th>02:00</th>\n",
       "      <th>...</th>\n",
       "      <th>21:30</th>\n",
       "      <th>21:45</th>\n",
       "      <th>22:00</th>\n",
       "      <th>22:15</th>\n",
       "      <th>22:30</th>\n",
       "      <th>22:45</th>\n",
       "      <th>23:00</th>\n",
       "      <th>23:15</th>\n",
       "      <th>23:30</th>\n",
       "      <th>23:45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1699791</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.006721</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.006778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.007086</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.006564</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.007301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1132611</td>\n",
       "      <td>0.081502</td>\n",
       "      <td>0.066426</td>\n",
       "      <td>0.052880</td>\n",
       "      <td>0.050020</td>\n",
       "      <td>0.048880</td>\n",
       "      <td>0.049070</td>\n",
       "      <td>0.045808</td>\n",
       "      <td>0.045223</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169567</td>\n",
       "      <td>0.168023</td>\n",
       "      <td>0.160208</td>\n",
       "      <td>0.143137</td>\n",
       "      <td>0.127647</td>\n",
       "      <td>0.127833</td>\n",
       "      <td>0.128325</td>\n",
       "      <td>0.122728</td>\n",
       "      <td>0.121205</td>\n",
       "      <td>0.123844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90001164</td>\n",
       "      <td>0.401711</td>\n",
       "      <td>0.384288</td>\n",
       "      <td>0.361851</td>\n",
       "      <td>0.366764</td>\n",
       "      <td>0.380571</td>\n",
       "      <td>0.394248</td>\n",
       "      <td>0.395500</td>\n",
       "      <td>0.397604</td>\n",
       "      <td>0.413474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362813</td>\n",
       "      <td>0.323424</td>\n",
       "      <td>0.331992</td>\n",
       "      <td>0.408344</td>\n",
       "      <td>0.434022</td>\n",
       "      <td>0.442570</td>\n",
       "      <td>0.448411</td>\n",
       "      <td>0.444237</td>\n",
       "      <td>0.445044</td>\n",
       "      <td>0.443231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10016608</td>\n",
       "      <td>0.854030</td>\n",
       "      <td>0.860039</td>\n",
       "      <td>0.830305</td>\n",
       "      <td>0.837424</td>\n",
       "      <td>0.835443</td>\n",
       "      <td>0.828038</td>\n",
       "      <td>0.830388</td>\n",
       "      <td>0.839721</td>\n",
       "      <td>0.834598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864170</td>\n",
       "      <td>0.826169</td>\n",
       "      <td>0.786728</td>\n",
       "      <td>0.777121</td>\n",
       "      <td>0.819110</td>\n",
       "      <td>0.813144</td>\n",
       "      <td>0.852251</td>\n",
       "      <td>0.857946</td>\n",
       "      <td>0.860029</td>\n",
       "      <td>0.867627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90002274</td>\n",
       "      <td>0.780804</td>\n",
       "      <td>0.824971</td>\n",
       "      <td>0.831780</td>\n",
       "      <td>0.820684</td>\n",
       "      <td>0.824391</td>\n",
       "      <td>0.835201</td>\n",
       "      <td>0.801928</td>\n",
       "      <td>0.818192</td>\n",
       "      <td>0.805883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.599305</td>\n",
       "      <td>0.555315</td>\n",
       "      <td>0.552093</td>\n",
       "      <td>0.568132</td>\n",
       "      <td>0.581777</td>\n",
       "      <td>0.623256</td>\n",
       "      <td>0.693446</td>\n",
       "      <td>0.736397</td>\n",
       "      <td>0.793248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>SIGMAPLAST</td>\n",
       "      <td>0.629019</td>\n",
       "      <td>0.630376</td>\n",
       "      <td>0.633878</td>\n",
       "      <td>0.628827</td>\n",
       "      <td>0.628891</td>\n",
       "      <td>0.645276</td>\n",
       "      <td>0.620338</td>\n",
       "      <td>0.625429</td>\n",
       "      <td>0.605990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714449</td>\n",
       "      <td>0.731757</td>\n",
       "      <td>0.722260</td>\n",
       "      <td>0.691284</td>\n",
       "      <td>0.708349</td>\n",
       "      <td>0.708756</td>\n",
       "      <td>0.718092</td>\n",
       "      <td>0.726780</td>\n",
       "      <td>0.729823</td>\n",
       "      <td>0.736136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>SINTOFIL</td>\n",
       "      <td>0.570382</td>\n",
       "      <td>0.585197</td>\n",
       "      <td>0.573659</td>\n",
       "      <td>0.597055</td>\n",
       "      <td>0.576146</td>\n",
       "      <td>0.579117</td>\n",
       "      <td>0.577594</td>\n",
       "      <td>0.575732</td>\n",
       "      <td>0.573957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718854</td>\n",
       "      <td>0.682750</td>\n",
       "      <td>0.618568</td>\n",
       "      <td>0.668834</td>\n",
       "      <td>0.652609</td>\n",
       "      <td>0.609928</td>\n",
       "      <td>0.658959</td>\n",
       "      <td>0.648654</td>\n",
       "      <td>0.672968</td>\n",
       "      <td>0.686380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>SOCIEDAD INDUSTRIAL RELI  CYRANO</td>\n",
       "      <td>0.507827</td>\n",
       "      <td>0.548428</td>\n",
       "      <td>0.602141</td>\n",
       "      <td>0.641924</td>\n",
       "      <td>0.676887</td>\n",
       "      <td>0.664849</td>\n",
       "      <td>0.604600</td>\n",
       "      <td>0.519819</td>\n",
       "      <td>0.460527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143328</td>\n",
       "      <td>0.236751</td>\n",
       "      <td>0.309762</td>\n",
       "      <td>0.366178</td>\n",
       "      <td>0.461476</td>\n",
       "      <td>0.496907</td>\n",
       "      <td>0.532044</td>\n",
       "      <td>0.538810</td>\n",
       "      <td>0.510710</td>\n",
       "      <td>0.507754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>TEXTILES TEXSA</td>\n",
       "      <td>0.649134</td>\n",
       "      <td>0.655870</td>\n",
       "      <td>0.673144</td>\n",
       "      <td>0.686085</td>\n",
       "      <td>0.654700</td>\n",
       "      <td>0.630197</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.622630</td>\n",
       "      <td>0.569756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658813</td>\n",
       "      <td>0.661239</td>\n",
       "      <td>0.658601</td>\n",
       "      <td>0.646816</td>\n",
       "      <td>0.667399</td>\n",
       "      <td>0.659044</td>\n",
       "      <td>0.700041</td>\n",
       "      <td>0.704060</td>\n",
       "      <td>0.703403</td>\n",
       "      <td>0.681430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>VICUNHA ECUADOR</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.016489</td>\n",
       "      <td>0.028610</td>\n",
       "      <td>0.032117</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>0.046931</td>\n",
       "      <td>0.032595</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235963</td>\n",
       "      <td>0.141392</td>\n",
       "      <td>0.092120</td>\n",
       "      <td>0.123175</td>\n",
       "      <td>0.128275</td>\n",
       "      <td>0.147159</td>\n",
       "      <td>0.176647</td>\n",
       "      <td>0.147915</td>\n",
       "      <td>0.163142</td>\n",
       "      <td>0.131872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Cliente     00:00     00:15     00:30     00:45  \\\n",
       "0                             1699791  0.006641  0.006721  0.006521  0.005803   \n",
       "1                             1132611  0.081502  0.066426  0.052880  0.050020   \n",
       "2                            90001164  0.401711  0.384288  0.361851  0.366764   \n",
       "3                            10016608  0.854030  0.860039  0.830305  0.837424   \n",
       "4                            90002274  0.780804  0.824971  0.831780  0.820684   \n",
       "..                                ...       ...       ...       ...       ...   \n",
       "384                        SIGMAPLAST  0.629019  0.630376  0.633878  0.628827   \n",
       "385                          SINTOFIL  0.570382  0.585197  0.573659  0.597055   \n",
       "386  SOCIEDAD INDUSTRIAL RELI  CYRANO  0.507827  0.548428  0.602141  0.641924   \n",
       "387                    TEXTILES TEXSA  0.649134  0.655870  0.673144  0.686085   \n",
       "388                   VICUNHA ECUADOR  0.018601  0.016489  0.028610  0.032117   \n",
       "\n",
       "        01:00     01:15     01:30     01:45     02:00  ...     21:30  \\\n",
       "0    0.006295  0.006814  0.006193  0.006814  0.006778  ...  0.007477   \n",
       "1    0.048880  0.049070  0.045808  0.045223  0.045371  ...  0.169567   \n",
       "2    0.380571  0.394248  0.395500  0.397604  0.413474  ...  0.362813   \n",
       "3    0.835443  0.828038  0.830388  0.839721  0.834598  ...  0.864170   \n",
       "4    0.824391  0.835201  0.801928  0.818192  0.805883  ...  0.663551   \n",
       "..        ...       ...       ...       ...       ...  ...       ...   \n",
       "384  0.628891  0.645276  0.620338  0.625429  0.605990  ...  0.714449   \n",
       "385  0.576146  0.579117  0.577594  0.575732  0.573957  ...  0.718854   \n",
       "386  0.676887  0.664849  0.604600  0.519819  0.460527  ...  0.143328   \n",
       "387  0.654700  0.630197  0.620000  0.622630  0.569756  ...  0.658813   \n",
       "388  0.038422  0.046931  0.032595  0.044854  0.015252  ...  0.235963   \n",
       "\n",
       "        21:45     22:00     22:15     22:30     22:45     23:00     23:15  \\\n",
       "0    0.007086  0.008579  0.007074  0.007934  0.006692  0.006564  0.007299   \n",
       "1    0.168023  0.160208  0.143137  0.127647  0.127833  0.128325  0.122728   \n",
       "2    0.323424  0.331992  0.408344  0.434022  0.442570  0.448411  0.444237   \n",
       "3    0.826169  0.786728  0.777121  0.819110  0.813144  0.852251  0.857946   \n",
       "4    0.599305  0.555315  0.552093  0.568132  0.581777  0.623256  0.693446   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "384  0.731757  0.722260  0.691284  0.708349  0.708756  0.718092  0.726780   \n",
       "385  0.682750  0.618568  0.668834  0.652609  0.609928  0.658959  0.648654   \n",
       "386  0.236751  0.309762  0.366178  0.461476  0.496907  0.532044  0.538810   \n",
       "387  0.661239  0.658601  0.646816  0.667399  0.659044  0.700041  0.704060   \n",
       "388  0.141392  0.092120  0.123175  0.128275  0.147159  0.176647  0.147915   \n",
       "\n",
       "        23:30     23:45  \n",
       "0    0.006337  0.007301  \n",
       "1    0.121205  0.123844  \n",
       "2    0.445044  0.443231  \n",
       "3    0.860029  0.867627  \n",
       "4    0.736397  0.793248  \n",
       "..        ...       ...  \n",
       "384  0.729823  0.736136  \n",
       "385  0.672968  0.686380  \n",
       "386  0.510710  0.507754  \n",
       "387  0.703403  0.681430  \n",
       "388  0.163142  0.131872  \n",
       "\n",
       "[389 rows x 97 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_registros_todas_las_curvas = pd.DataFrame(registros_curvas_todas)\n",
    "df_registros_todas_las_curvas.columns = columnas_df_todas_las_curvas\n",
    "df_registros_todas_las_curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cliente</th>\n",
       "      <th>00:00</th>\n",
       "      <th>00:15</th>\n",
       "      <th>00:30</th>\n",
       "      <th>00:45</th>\n",
       "      <th>01:00</th>\n",
       "      <th>01:15</th>\n",
       "      <th>01:30</th>\n",
       "      <th>01:45</th>\n",
       "      <th>02:00</th>\n",
       "      <th>...</th>\n",
       "      <th>21:30</th>\n",
       "      <th>21:45</th>\n",
       "      <th>22:00</th>\n",
       "      <th>22:15</th>\n",
       "      <th>22:30</th>\n",
       "      <th>22:45</th>\n",
       "      <th>23:00</th>\n",
       "      <th>23:15</th>\n",
       "      <th>23:30</th>\n",
       "      <th>23:45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>90000662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cliente  00:00  00:15  00:30  00:45  01:00  01:15  01:30  01:45  02:00  \\\n",
       "234  90000662    0.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "     ...  21:30  21:45  22:00  22:15  22:30  22:45  23:00  23:15  23:30  23:45  \n",
       "234  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[1 rows x 97 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Verificar valores nulos\n",
    "df_registros_todas_las_curvas[df_registros_todas_las_curvas.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cliente</th>\n",
       "      <th>00:00</th>\n",
       "      <th>00:15</th>\n",
       "      <th>00:30</th>\n",
       "      <th>00:45</th>\n",
       "      <th>01:00</th>\n",
       "      <th>01:15</th>\n",
       "      <th>01:30</th>\n",
       "      <th>01:45</th>\n",
       "      <th>02:00</th>\n",
       "      <th>...</th>\n",
       "      <th>21:30</th>\n",
       "      <th>21:45</th>\n",
       "      <th>22:00</th>\n",
       "      <th>22:15</th>\n",
       "      <th>22:30</th>\n",
       "      <th>22:45</th>\n",
       "      <th>23:00</th>\n",
       "      <th>23:15</th>\n",
       "      <th>23:30</th>\n",
       "      <th>23:45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>90000664</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.019424</td>\n",
       "      <td>0.01805</td>\n",
       "      <td>0.01641</td>\n",
       "      <td>0.016649</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085344</td>\n",
       "      <td>0.079758</td>\n",
       "      <td>0.074629</td>\n",
       "      <td>0.065755</td>\n",
       "      <td>0.052652</td>\n",
       "      <td>0.04661</td>\n",
       "      <td>0.044091</td>\n",
       "      <td>0.035944</td>\n",
       "      <td>0.026084</td>\n",
       "      <td>0.020125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>90000664</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.019424</td>\n",
       "      <td>0.01805</td>\n",
       "      <td>0.01641</td>\n",
       "      <td>0.016649</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085344</td>\n",
       "      <td>0.079758</td>\n",
       "      <td>0.074629</td>\n",
       "      <td>0.065755</td>\n",
       "      <td>0.052652</td>\n",
       "      <td>0.04661</td>\n",
       "      <td>0.044091</td>\n",
       "      <td>0.035944</td>\n",
       "      <td>0.026084</td>\n",
       "      <td>0.020125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cliente     00:00     00:15    00:30    00:45     01:00     01:15  \\\n",
       "29   90000664  0.018723  0.019424  0.01805  0.01641  0.016649  0.013683   \n",
       "311  90000664  0.018723  0.019424  0.01805  0.01641  0.016649  0.013683   \n",
       "\n",
       "        01:30     01:45     02:00  ...     21:30     21:45     22:00  \\\n",
       "29   0.012931  0.012956  0.013109  ...  0.085344  0.079758  0.074629   \n",
       "311  0.012931  0.012956  0.013109  ...  0.085344  0.079758  0.074629   \n",
       "\n",
       "        22:15     22:30    22:45     23:00     23:15     23:30     23:45  \n",
       "29   0.065755  0.052652  0.04661  0.044091  0.035944  0.026084  0.020125  \n",
       "311  0.065755  0.052652  0.04661  0.044091  0.035944  0.026084  0.020125  \n",
       "\n",
       "[2 rows x 97 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Verificar duplicados\n",
    "df_registros_todas_las_curvas[\"Cliente\"] = df_registros_todas_las_curvas[\"Cliente\"].astype(\"string\")\n",
    "df_registros_todas_las_curvas[\"Cliente\"] = df_registros_todas_las_curvas[\"Cliente\"].apply(lambda x: x[1:] if x.startswith('0') else x)\n",
    "df_registros_todas_las_curvas[df_registros_todas_las_curvas[\"Cliente\"].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excluir filas con valores nulos o filas duplicadas\n",
    "excluir = ['90000662',\n",
    "           '090000664']\n",
    "df_registros_todas_las_curvas = df_registros_todas_las_curvas[~df_registros_todas_las_curvas[\"Cliente\"].isin(excluir)]\n",
    "df_registros_todas_las_curvas = df_registros_todas_las_curvas.drop_duplicates(subset=\"Cliente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 97)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_registros_todas_las_curvas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def obtener_cliente_db():\n",
    "    # Cargar las variables del archivo .env\n",
    "    load_dotenv()\n",
    "\n",
    "    # Obtener las credenciales y el cluster de MongoDB\n",
    "    username = os.getenv(\"DB_USER_T\")\n",
    "    password = os.getenv(\"DB_PASS_T\")\n",
    "    cluster = os.getenv(\"DB_CLUSTER_T\")\n",
    "\n",
    "    # Construir la uri con las credenciales\n",
    "    uri = f\"mongodb+srv://{username}:{password}@{cluster.lower()}.gypwd.mongodb.net/?retryWrites=true&w=majority&appName={cluster}\"\n",
    "\n",
    "    # Crear un cliente y conectarlo al servidor\n",
    "    client = MongoClient(uri, \n",
    "                        server_api=ServerApi('1'),\n",
    "                        connectTimeoutMS=60000,\n",
    "                        socketTimeoutMS=60000,\n",
    "                        serverSelectionTimeoutMS=60000,\n",
    "                        tls=True)\n",
    "\n",
    "    # Si el cliente existe, retornarlo\n",
    "    if client is not None:\n",
    "        return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertManyResult([ObjectId('687154c6b4f8ddf88278aaa0'), ObjectId('687154c6b4f8ddf88278aaa1'), ObjectId('687154c6b4f8ddf88278aaa2'), ObjectId('687154c6b4f8ddf88278aaa3'), ObjectId('687154c6b4f8ddf88278aaa4'), ObjectId('687154c6b4f8ddf88278aaa5'), ObjectId('687154c6b4f8ddf88278aaa6'), ObjectId('687154c6b4f8ddf88278aaa7'), ObjectId('687154c6b4f8ddf88278aaa8'), ObjectId('687154c6b4f8ddf88278aaa9'), ObjectId('687154c6b4f8ddf88278aaaa'), ObjectId('687154c6b4f8ddf88278aaab'), ObjectId('687154c6b4f8ddf88278aaac'), ObjectId('687154c6b4f8ddf88278aaad'), ObjectId('687154c6b4f8ddf88278aaae'), ObjectId('687154c6b4f8ddf88278aaaf'), ObjectId('687154c6b4f8ddf88278aab0'), ObjectId('687154c6b4f8ddf88278aab1'), ObjectId('687154c6b4f8ddf88278aab2'), ObjectId('687154c6b4f8ddf88278aab3'), ObjectId('687154c6b4f8ddf88278aab4'), ObjectId('687154c6b4f8ddf88278aab5'), ObjectId('687154c6b4f8ddf88278aab6'), ObjectId('687154c6b4f8ddf88278aab7'), ObjectId('687154c6b4f8ddf88278aab8'), ObjectId('687154c6b4f8ddf88278aab9'), ObjectId('687154c6b4f8ddf88278aaba'), ObjectId('687154c6b4f8ddf88278aabb'), ObjectId('687154c6b4f8ddf88278aabc'), ObjectId('687154c6b4f8ddf88278aabd'), ObjectId('687154c6b4f8ddf88278aabe'), ObjectId('687154c6b4f8ddf88278aabf'), ObjectId('687154c6b4f8ddf88278aac0'), ObjectId('687154c6b4f8ddf88278aac1'), ObjectId('687154c6b4f8ddf88278aac2'), ObjectId('687154c6b4f8ddf88278aac3'), ObjectId('687154c6b4f8ddf88278aac4'), ObjectId('687154c6b4f8ddf88278aac5'), ObjectId('687154c6b4f8ddf88278aac6'), ObjectId('687154c6b4f8ddf88278aac7'), ObjectId('687154c6b4f8ddf88278aac8'), ObjectId('687154c6b4f8ddf88278aac9'), ObjectId('687154c6b4f8ddf88278aaca'), ObjectId('687154c6b4f8ddf88278aacb'), ObjectId('687154c6b4f8ddf88278aacc'), ObjectId('687154c6b4f8ddf88278aacd'), ObjectId('687154c6b4f8ddf88278aace'), ObjectId('687154c6b4f8ddf88278aacf'), ObjectId('687154c6b4f8ddf88278aad0'), ObjectId('687154c6b4f8ddf88278aad1'), ObjectId('687154c6b4f8ddf88278aad2'), ObjectId('687154c6b4f8ddf88278aad3'), ObjectId('687154c6b4f8ddf88278aad4'), ObjectId('687154c6b4f8ddf88278aad5'), ObjectId('687154c6b4f8ddf88278aad6'), ObjectId('687154c6b4f8ddf88278aad7'), ObjectId('687154c6b4f8ddf88278aad8'), ObjectId('687154c6b4f8ddf88278aad9'), ObjectId('687154c6b4f8ddf88278aada'), ObjectId('687154c6b4f8ddf88278aadb'), ObjectId('687154c6b4f8ddf88278aadc'), ObjectId('687154c6b4f8ddf88278aadd'), ObjectId('687154c6b4f8ddf88278aade'), ObjectId('687154c6b4f8ddf88278aadf'), ObjectId('687154c6b4f8ddf88278aae0'), ObjectId('687154c6b4f8ddf88278aae1'), ObjectId('687154c6b4f8ddf88278aae2'), ObjectId('687154c6b4f8ddf88278aae3'), ObjectId('687154c6b4f8ddf88278aae4'), ObjectId('687154c6b4f8ddf88278aae5'), ObjectId('687154c6b4f8ddf88278aae6'), ObjectId('687154c6b4f8ddf88278aae7'), ObjectId('687154c6b4f8ddf88278aae8'), ObjectId('687154c6b4f8ddf88278aae9'), ObjectId('687154c6b4f8ddf88278aaea'), ObjectId('687154c6b4f8ddf88278aaeb'), ObjectId('687154c6b4f8ddf88278aaec'), ObjectId('687154c6b4f8ddf88278aaed'), ObjectId('687154c6b4f8ddf88278aaee'), ObjectId('687154c6b4f8ddf88278aaef'), ObjectId('687154c6b4f8ddf88278aaf0'), ObjectId('687154c6b4f8ddf88278aaf1'), ObjectId('687154c6b4f8ddf88278aaf2'), ObjectId('687154c6b4f8ddf88278aaf3'), ObjectId('687154c6b4f8ddf88278aaf4'), ObjectId('687154c6b4f8ddf88278aaf5'), ObjectId('687154c6b4f8ddf88278aaf6'), ObjectId('687154c6b4f8ddf88278aaf7'), ObjectId('687154c6b4f8ddf88278aaf8'), ObjectId('687154c6b4f8ddf88278aaf9'), ObjectId('687154c6b4f8ddf88278aafa'), ObjectId('687154c6b4f8ddf88278aafb'), ObjectId('687154c6b4f8ddf88278aafc'), ObjectId('687154c6b4f8ddf88278aafd'), ObjectId('687154c6b4f8ddf88278aafe'), ObjectId('687154c6b4f8ddf88278aaff'), ObjectId('687154c6b4f8ddf88278ab00'), ObjectId('687154c6b4f8ddf88278ab01'), ObjectId('687154c6b4f8ddf88278ab02'), ObjectId('687154c6b4f8ddf88278ab03'), ObjectId('687154c6b4f8ddf88278ab04'), ObjectId('687154c6b4f8ddf88278ab05'), ObjectId('687154c6b4f8ddf88278ab06'), ObjectId('687154c6b4f8ddf88278ab07'), ObjectId('687154c6b4f8ddf88278ab08'), ObjectId('687154c6b4f8ddf88278ab09'), ObjectId('687154c6b4f8ddf88278ab0a'), ObjectId('687154c6b4f8ddf88278ab0b'), ObjectId('687154c6b4f8ddf88278ab0c'), ObjectId('687154c6b4f8ddf88278ab0d'), ObjectId('687154c6b4f8ddf88278ab0e'), ObjectId('687154c6b4f8ddf88278ab0f'), ObjectId('687154c6b4f8ddf88278ab10'), ObjectId('687154c6b4f8ddf88278ab11'), ObjectId('687154c6b4f8ddf88278ab12'), ObjectId('687154c6b4f8ddf88278ab13'), ObjectId('687154c6b4f8ddf88278ab14'), ObjectId('687154c6b4f8ddf88278ab15'), ObjectId('687154c6b4f8ddf88278ab16'), ObjectId('687154c6b4f8ddf88278ab17'), ObjectId('687154c6b4f8ddf88278ab18'), ObjectId('687154c6b4f8ddf88278ab19'), ObjectId('687154c6b4f8ddf88278ab1a'), ObjectId('687154c6b4f8ddf88278ab1b'), ObjectId('687154c6b4f8ddf88278ab1c'), ObjectId('687154c6b4f8ddf88278ab1d'), ObjectId('687154c6b4f8ddf88278ab1e'), ObjectId('687154c6b4f8ddf88278ab1f'), ObjectId('687154c6b4f8ddf88278ab20'), ObjectId('687154c6b4f8ddf88278ab21'), ObjectId('687154c6b4f8ddf88278ab22'), ObjectId('687154c6b4f8ddf88278ab23'), ObjectId('687154c6b4f8ddf88278ab24'), ObjectId('687154c6b4f8ddf88278ab25'), ObjectId('687154c6b4f8ddf88278ab26'), ObjectId('687154c6b4f8ddf88278ab27'), ObjectId('687154c6b4f8ddf88278ab28'), ObjectId('687154c6b4f8ddf88278ab29'), ObjectId('687154c6b4f8ddf88278ab2a'), ObjectId('687154c6b4f8ddf88278ab2b'), ObjectId('687154c6b4f8ddf88278ab2c'), ObjectId('687154c6b4f8ddf88278ab2d'), ObjectId('687154c6b4f8ddf88278ab2e'), ObjectId('687154c6b4f8ddf88278ab2f'), ObjectId('687154c6b4f8ddf88278ab30'), ObjectId('687154c6b4f8ddf88278ab31'), ObjectId('687154c6b4f8ddf88278ab32'), ObjectId('687154c6b4f8ddf88278ab33'), ObjectId('687154c6b4f8ddf88278ab34'), ObjectId('687154c6b4f8ddf88278ab35'), ObjectId('687154c6b4f8ddf88278ab36'), ObjectId('687154c6b4f8ddf88278ab37'), ObjectId('687154c6b4f8ddf88278ab38'), ObjectId('687154c6b4f8ddf88278ab39'), ObjectId('687154c6b4f8ddf88278ab3a'), ObjectId('687154c6b4f8ddf88278ab3b'), ObjectId('687154c6b4f8ddf88278ab3c'), ObjectId('687154c6b4f8ddf88278ab3d'), ObjectId('687154c6b4f8ddf88278ab3e'), ObjectId('687154c6b4f8ddf88278ab3f'), ObjectId('687154c6b4f8ddf88278ab40'), ObjectId('687154c6b4f8ddf88278ab41'), ObjectId('687154c6b4f8ddf88278ab42'), ObjectId('687154c6b4f8ddf88278ab43'), ObjectId('687154c6b4f8ddf88278ab44'), ObjectId('687154c6b4f8ddf88278ab45'), ObjectId('687154c6b4f8ddf88278ab46'), ObjectId('687154c6b4f8ddf88278ab47'), ObjectId('687154c6b4f8ddf88278ab48'), ObjectId('687154c6b4f8ddf88278ab49'), ObjectId('687154c6b4f8ddf88278ab4a'), ObjectId('687154c6b4f8ddf88278ab4b'), ObjectId('687154c6b4f8ddf88278ab4c'), ObjectId('687154c6b4f8ddf88278ab4d'), ObjectId('687154c6b4f8ddf88278ab4e'), ObjectId('687154c6b4f8ddf88278ab4f'), ObjectId('687154c6b4f8ddf88278ab50'), ObjectId('687154c6b4f8ddf88278ab51'), ObjectId('687154c6b4f8ddf88278ab52'), ObjectId('687154c6b4f8ddf88278ab53'), ObjectId('687154c6b4f8ddf88278ab54'), ObjectId('687154c6b4f8ddf88278ab55'), ObjectId('687154c6b4f8ddf88278ab56'), ObjectId('687154c6b4f8ddf88278ab57'), ObjectId('687154c6b4f8ddf88278ab58'), ObjectId('687154c6b4f8ddf88278ab59'), ObjectId('687154c6b4f8ddf88278ab5a'), ObjectId('687154c6b4f8ddf88278ab5b'), ObjectId('687154c6b4f8ddf88278ab5c'), ObjectId('687154c6b4f8ddf88278ab5d'), ObjectId('687154c6b4f8ddf88278ab5e'), ObjectId('687154c6b4f8ddf88278ab5f'), ObjectId('687154c6b4f8ddf88278ab60'), ObjectId('687154c6b4f8ddf88278ab61'), ObjectId('687154c6b4f8ddf88278ab62'), ObjectId('687154c6b4f8ddf88278ab63'), ObjectId('687154c6b4f8ddf88278ab64'), ObjectId('687154c6b4f8ddf88278ab65'), ObjectId('687154c6b4f8ddf88278ab66'), ObjectId('687154c6b4f8ddf88278ab67'), ObjectId('687154c6b4f8ddf88278ab68'), ObjectId('687154c6b4f8ddf88278ab69'), ObjectId('687154c6b4f8ddf88278ab6a'), ObjectId('687154c6b4f8ddf88278ab6b'), ObjectId('687154c6b4f8ddf88278ab6c'), ObjectId('687154c6b4f8ddf88278ab6d'), ObjectId('687154c6b4f8ddf88278ab6e'), ObjectId('687154c6b4f8ddf88278ab6f'), ObjectId('687154c6b4f8ddf88278ab70'), ObjectId('687154c6b4f8ddf88278ab71'), ObjectId('687154c6b4f8ddf88278ab72'), ObjectId('687154c6b4f8ddf88278ab73'), ObjectId('687154c6b4f8ddf88278ab74'), ObjectId('687154c6b4f8ddf88278ab75'), ObjectId('687154c6b4f8ddf88278ab76'), ObjectId('687154c6b4f8ddf88278ab77'), ObjectId('687154c6b4f8ddf88278ab78'), ObjectId('687154c6b4f8ddf88278ab79'), ObjectId('687154c6b4f8ddf88278ab7a'), ObjectId('687154c6b4f8ddf88278ab7b'), ObjectId('687154c6b4f8ddf88278ab7c'), ObjectId('687154c6b4f8ddf88278ab7d'), ObjectId('687154c6b4f8ddf88278ab7e'), ObjectId('687154c6b4f8ddf88278ab7f'), ObjectId('687154c6b4f8ddf88278ab80'), ObjectId('687154c6b4f8ddf88278ab81'), ObjectId('687154c6b4f8ddf88278ab82'), ObjectId('687154c6b4f8ddf88278ab83'), ObjectId('687154c6b4f8ddf88278ab84'), ObjectId('687154c6b4f8ddf88278ab85'), ObjectId('687154c6b4f8ddf88278ab86'), ObjectId('687154c6b4f8ddf88278ab87'), ObjectId('687154c6b4f8ddf88278ab88'), ObjectId('687154c6b4f8ddf88278ab89'), ObjectId('687154c6b4f8ddf88278ab8a'), ObjectId('687154c6b4f8ddf88278ab8b'), ObjectId('687154c6b4f8ddf88278ab8c'), ObjectId('687154c6b4f8ddf88278ab8d'), ObjectId('687154c6b4f8ddf88278ab8e'), ObjectId('687154c6b4f8ddf88278ab8f'), ObjectId('687154c6b4f8ddf88278ab90'), ObjectId('687154c6b4f8ddf88278ab91'), ObjectId('687154c6b4f8ddf88278ab92'), ObjectId('687154c6b4f8ddf88278ab93'), ObjectId('687154c6b4f8ddf88278ab94'), ObjectId('687154c6b4f8ddf88278ab95'), ObjectId('687154c6b4f8ddf88278ab96'), ObjectId('687154c6b4f8ddf88278ab97'), ObjectId('687154c6b4f8ddf88278ab98'), ObjectId('687154c6b4f8ddf88278ab99'), ObjectId('687154c6b4f8ddf88278ab9a'), ObjectId('687154c6b4f8ddf88278ab9b'), ObjectId('687154c6b4f8ddf88278ab9c'), ObjectId('687154c6b4f8ddf88278ab9d'), ObjectId('687154c6b4f8ddf88278ab9e'), ObjectId('687154c6b4f8ddf88278ab9f'), ObjectId('687154c6b4f8ddf88278aba0'), ObjectId('687154c6b4f8ddf88278aba1'), ObjectId('687154c6b4f8ddf88278aba2'), ObjectId('687154c6b4f8ddf88278aba3'), ObjectId('687154c6b4f8ddf88278aba4'), ObjectId('687154c6b4f8ddf88278aba5'), ObjectId('687154c6b4f8ddf88278aba6'), ObjectId('687154c6b4f8ddf88278aba7'), ObjectId('687154c6b4f8ddf88278aba8'), ObjectId('687154c6b4f8ddf88278aba9'), ObjectId('687154c6b4f8ddf88278abaa'), ObjectId('687154c6b4f8ddf88278abab'), ObjectId('687154c6b4f8ddf88278abac'), ObjectId('687154c6b4f8ddf88278abad'), ObjectId('687154c6b4f8ddf88278abae'), ObjectId('687154c6b4f8ddf88278abaf'), ObjectId('687154c6b4f8ddf88278abb0'), ObjectId('687154c6b4f8ddf88278abb1'), ObjectId('687154c6b4f8ddf88278abb2'), ObjectId('687154c6b4f8ddf88278abb3'), ObjectId('687154c6b4f8ddf88278abb4'), ObjectId('687154c6b4f8ddf88278abb5'), ObjectId('687154c6b4f8ddf88278abb6'), ObjectId('687154c6b4f8ddf88278abb7'), ObjectId('687154c6b4f8ddf88278abb8'), ObjectId('687154c6b4f8ddf88278abb9'), ObjectId('687154c6b4f8ddf88278abba'), ObjectId('687154c6b4f8ddf88278abbb'), ObjectId('687154c6b4f8ddf88278abbc'), ObjectId('687154c6b4f8ddf88278abbd'), ObjectId('687154c6b4f8ddf88278abbe'), ObjectId('687154c6b4f8ddf88278abbf'), ObjectId('687154c6b4f8ddf88278abc0'), ObjectId('687154c6b4f8ddf88278abc1'), ObjectId('687154c6b4f8ddf88278abc2'), ObjectId('687154c6b4f8ddf88278abc3'), ObjectId('687154c6b4f8ddf88278abc4'), ObjectId('687154c6b4f8ddf88278abc5'), ObjectId('687154c6b4f8ddf88278abc6'), ObjectId('687154c6b4f8ddf88278abc7'), ObjectId('687154c6b4f8ddf88278abc8'), ObjectId('687154c6b4f8ddf88278abc9'), ObjectId('687154c6b4f8ddf88278abca'), ObjectId('687154c6b4f8ddf88278abcb'), ObjectId('687154c6b4f8ddf88278abcc'), ObjectId('687154c6b4f8ddf88278abcd'), ObjectId('687154c6b4f8ddf88278abce'), ObjectId('687154c6b4f8ddf88278abcf'), ObjectId('687154c6b4f8ddf88278abd0'), ObjectId('687154c6b4f8ddf88278abd1'), ObjectId('687154c6b4f8ddf88278abd2'), ObjectId('687154c6b4f8ddf88278abd3'), ObjectId('687154c6b4f8ddf88278abd4'), ObjectId('687154c6b4f8ddf88278abd5'), ObjectId('687154c6b4f8ddf88278abd6'), ObjectId('687154c6b4f8ddf88278abd7'), ObjectId('687154c6b4f8ddf88278abd8'), ObjectId('687154c6b4f8ddf88278abd9'), ObjectId('687154c6b4f8ddf88278abda'), ObjectId('687154c6b4f8ddf88278abdb'), ObjectId('687154c6b4f8ddf88278abdc'), ObjectId('687154c6b4f8ddf88278abdd'), ObjectId('687154c6b4f8ddf88278abde'), ObjectId('687154c6b4f8ddf88278abdf'), ObjectId('687154c6b4f8ddf88278abe0'), ObjectId('687154c6b4f8ddf88278abe1'), ObjectId('687154c6b4f8ddf88278abe2'), ObjectId('687154c6b4f8ddf88278abe3'), ObjectId('687154c6b4f8ddf88278abe4'), ObjectId('687154c6b4f8ddf88278abe5'), ObjectId('687154c6b4f8ddf88278abe6'), ObjectId('687154c6b4f8ddf88278abe7'), ObjectId('687154c6b4f8ddf88278abe8'), ObjectId('687154c6b4f8ddf88278abe9'), ObjectId('687154c6b4f8ddf88278abea'), ObjectId('687154c6b4f8ddf88278abeb'), ObjectId('687154c6b4f8ddf88278abec'), ObjectId('687154c6b4f8ddf88278abed'), ObjectId('687154c6b4f8ddf88278abee'), ObjectId('687154c6b4f8ddf88278abef'), ObjectId('687154c6b4f8ddf88278abf0'), ObjectId('687154c6b4f8ddf88278abf1'), ObjectId('687154c6b4f8ddf88278abf2'), ObjectId('687154c6b4f8ddf88278abf3'), ObjectId('687154c6b4f8ddf88278abf4'), ObjectId('687154c6b4f8ddf88278abf5'), ObjectId('687154c6b4f8ddf88278abf6'), ObjectId('687154c6b4f8ddf88278abf7'), ObjectId('687154c6b4f8ddf88278abf8'), ObjectId('687154c6b4f8ddf88278abf9'), ObjectId('687154c6b4f8ddf88278abfa'), ObjectId('687154c6b4f8ddf88278abfb'), ObjectId('687154c6b4f8ddf88278abfc'), ObjectId('687154c6b4f8ddf88278abfd'), ObjectId('687154c6b4f8ddf88278abfe'), ObjectId('687154c6b4f8ddf88278abff'), ObjectId('687154c6b4f8ddf88278ac00'), ObjectId('687154c6b4f8ddf88278ac01'), ObjectId('687154c6b4f8ddf88278ac02'), ObjectId('687154c6b4f8ddf88278ac03'), ObjectId('687154c6b4f8ddf88278ac04'), ObjectId('687154c6b4f8ddf88278ac05'), ObjectId('687154c6b4f8ddf88278ac06'), ObjectId('687154c6b4f8ddf88278ac07'), ObjectId('687154c6b4f8ddf88278ac08'), ObjectId('687154c6b4f8ddf88278ac09'), ObjectId('687154c6b4f8ddf88278ac0a'), ObjectId('687154c6b4f8ddf88278ac0b'), ObjectId('687154c6b4f8ddf88278ac0c'), ObjectId('687154c6b4f8ddf88278ac0d'), ObjectId('687154c6b4f8ddf88278ac0e'), ObjectId('687154c6b4f8ddf88278ac0f'), ObjectId('687154c6b4f8ddf88278ac10'), ObjectId('687154c6b4f8ddf88278ac11'), ObjectId('687154c6b4f8ddf88278ac12'), ObjectId('687154c6b4f8ddf88278ac13'), ObjectId('687154c6b4f8ddf88278ac14'), ObjectId('687154c6b4f8ddf88278ac15'), ObjectId('687154c6b4f8ddf88278ac16'), ObjectId('687154c6b4f8ddf88278ac17'), ObjectId('687154c6b4f8ddf88278ac18'), ObjectId('687154c6b4f8ddf88278ac19'), ObjectId('687154c6b4f8ddf88278ac1a'), ObjectId('687154c6b4f8ddf88278ac1b'), ObjectId('687154c6b4f8ddf88278ac1c'), ObjectId('687154c6b4f8ddf88278ac1d'), ObjectId('687154c6b4f8ddf88278ac1e'), ObjectId('687154c6b4f8ddf88278ac1f'), ObjectId('687154c6b4f8ddf88278ac20'), ObjectId('687154c6b4f8ddf88278ac21'), ObjectId('687154c6b4f8ddf88278ac22')], acknowledged=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener cliente para conectar a la db\n",
    "db_cliente = obtener_cliente_db()\n",
    "\n",
    "# Convertir el dataframe a diccionario\n",
    "datos_insertar = df_registros_todas_las_curvas.to_dict(orient='records')\n",
    "\n",
    "# Eliminar cualquier documento existente en la colección\n",
    "db_cliente.CurvasTipo.CurvasTipo_15m_v2.delete_many({})\n",
    "\n",
    "# Creación de índice para el campo de la fecha\n",
    "db_cliente.CurvasTipo.CurvasTipo_15m_v2.create_index([(\"Cliente\", 1)])\n",
    "\n",
    "# Insertar en la base de datos\n",
    "db_cliente.CurvasTipo.CurvasTipo_15m_v2.insert_many(datos_insertar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
